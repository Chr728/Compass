{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import image as mpimg\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import os\n",
    "import re\n",
    "import requests\n",
    "from PIL import Image\n",
    "from torchvision.transforms import ToTensor\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt     # to plot charts\n",
    "import numpy as np\n",
    "import pandas as pd                 # for data manipulation\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "import cv2                          # for image processing\n",
    "from io import BytesIO\n",
    "from tabulate import tabulate       # to print pretty tables\n",
    "import seaborn as sns\n",
    "import shutil\n",
    "\n",
    "# sklearn imports for metrics and dataset splitting\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# keras imports for image preprocessing\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# huggingface imports for model building \n",
    "import torch.nn as nn\n",
    "from transformers import ViTModel, ViTForImageClassification, TrainingArguments, Trainer, \\\n",
    "  default_data_collator, EarlyStoppingCallback, ViTConfig, AutoImageProcessor, ViTImageProcessor, AutoModel \n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "\n",
    "# keras imports for early stoppage and model checkpointing\n",
    "from torchvision.transforms import ToTensor, Resize\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.io import read_image\n",
    "\n",
    "from datasets import load_dataset, load_metric, Features, ClassLabel, Array3D, Dataset\n",
    "import datasets\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "from safetensors.numpy import  load_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_URL = 'https://data.lhncbc.nlm.nih.gov/public/Pills/'\n",
    "directory = \"dataset\"\n",
    "train_dir = \"training20_set\"\n",
    "test_dir = \"testing20_set\"\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import (Top 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the csv files\n",
    "csv_file_top20 = \"./top20.csv\"\n",
    "csv_file = \"./table.csv\"\n",
    "csv_file2 = \"./directory_consumer_grade_images.xlsx\"\n",
    "top20_df = pd.read_csv(csv_file_top20)\n",
    "table_df = pd.read_csv(csv_file)\n",
    "directory_df = pd.read_excel(csv_file2)\n",
    "\n",
    "top20_list = top20_df['Name'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove .wmv files\n",
    "directory_df = directory_df[~directory_df['Image'].str.contains('.wmv', case=False, na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to get the base label\n",
    "def get_base_label(label):\n",
    "    for item in top20_list:\n",
    "        if item.lower() in label.lower():\n",
    "            return item\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the top 20 medications in the two datasets\n",
    "# find matches in table_df\n",
    "matches_in_table_df = pd.DataFrame()\n",
    "for item in top20_list:\n",
    "    item = item.upper()\n",
    "    matches = table_df[table_df['name'].fillna('').str.contains(item, case=False, na=False) ]\n",
    "    matches_in_table_df = pd.concat([matches_in_table_df, matches])\n",
    "\n",
    "# find matches in directory_df\n",
    "matches_in_directory_df = pd.DataFrame()\n",
    "for item in top20_list:\n",
    "    item = item.upper()\n",
    "    matches = directory_df[directory_df['Name'].fillna('').str.contains(item, case=False, na=False) ]\n",
    "    matches_in_directory_df = pd.concat([matches_in_directory_df, matches])\n",
    "\n",
    "# generate the test set\n",
    "test_df = matches_in_directory_df[matches_in_directory_df['Layout'] == 'C3PI_Test']\n",
    "\n",
    "# keep only necessary images\n",
    "matches_in_directory_df = matches_in_directory_df[matches_in_directory_df['Layout'].isin(['MC_API_NLMIMAGE_V1.3', 'MC_CHALLENGE_V1.0'])]\n",
    "\n",
    "# remove unnecessary columns and rename columns\n",
    "matches_in_table_df = matches_in_table_df[['name', 'nlmImageFileName']]\n",
    "matches_in_table_df = matches_in_table_df.rename(columns={'name': 'labels', 'nlmImageFileName': 'image_paths'})\n",
    "matches_in_directory_df = matches_in_directory_df[['Image', 'Name']]\n",
    "matches_in_directory_df = matches_in_directory_df.rename(columns={'Image': 'image_paths', 'Name': 'labels'})\n",
    "test_df = test_df[['Image', 'Name']]\n",
    "test_df = test_df.rename(columns={'Image': 'image_paths', 'Name': 'labels'})\n",
    "\n",
    "# # Remove .wmv files\n",
    "# matches_in_table_df = matches_in_table_df[~matches_in_table_df['image_paths'].str.contains('.wmv', case=False, na=False, regex=True)]\n",
    "# matches_in_directory_df = matches_in_directory_df[~matches_in_directory_df['image_paths'].str.contains('.wmv', case=False, na=False, regex=True)]\n",
    "\n",
    "# add a base label column for the top 20 medications\n",
    "matches_in_table_df['base_label'] = matches_in_table_df['labels'].apply(get_base_label)\n",
    "matches_in_directory_df['base_label'] = matches_in_directory_df['labels'].apply(get_base_label)\n",
    "test_df['base_label'] = test_df['labels'].apply(get_base_label)\n",
    "\n",
    "# instantiate the label encoder\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(top20_list)\n",
    "\n",
    "# Transform the data in the dataframes\n",
    "matches_in_table_df['base_label'] = encoder.transform(matches_in_table_df['base_label'])\n",
    "matches_in_directory_df['base_label'] = encoder.transform(matches_in_directory_df['base_label'])\n",
    "test_df['base_label'] = encoder.transform(test_df['base_label'])\n",
    "\n",
    "top20_instances_df = pd.concat([matches_in_table_df, matches_in_directory_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp_df = test_df.copy()\n",
    "# test_df = top20_instances_df.copy()\n",
    "# top20_instances_df = temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top20_instances_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('training set size: ',top20_instances_df.size)\n",
    "print('test set size: ',test_df.size)\n",
    "print('number of unique labels: ',len(top20_instances_df['base_label'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top20_instances_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode the labels in top20_instances_df\n",
    "top20_instances_df['base_label'] = encoder.inverse_transform(top20_instances_df['base_label'])\n",
    "\n",
    "# Check if the data is imbalanced in the training set\n",
    "train_label_counts = top20_instances_df['base_label'].value_counts()\n",
    "print(train_label_counts)\n",
    "\n",
    "# Plot the label counts\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.bar(train_label_counts.index, train_label_counts.values, alpha=0.5, color='g')\n",
    "plt.title('Distribution of Base Labels (Training Set)')\n",
    "plt.xlabel('Base Label')\n",
    "plt.ylabel('Number of Labels')\n",
    "plt.xticks(rotation=90)\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Decode the labels in test_df\n",
    "test_df['base_label'] = encoder.inverse_transform(test_df['base_label'])\n",
    "\n",
    "# Check if the data is imbalanced in the test set\n",
    "test_label_counts = test_df['base_label'].value_counts()\n",
    "print(test_label_counts)\n",
    "\n",
    "# Plot the label counts for the test set\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.bar(test_label_counts.index, test_label_counts.values, alpha=0.5, color='b')\n",
    "plt.title('Distribution of Base Labels (Test Set)')\n",
    "plt.xlabel('Base Label')\n",
    "plt.ylabel('Number of Labels')\n",
    "plt.xticks(rotation=90)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-encode the labels\n",
    "top20_instances_df['base_label'] = encoder.transform(top20_instances_df['base_label'])\n",
    "test_df['base_label'] = encoder.transform(test_df['base_label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading the Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "website_url = 'https://data.lhncbc.nlm.nih.gov/public/Pills/'\n",
    "dataset_dir = './dataset'\n",
    "training_dir = './training20_set'\n",
    "\n",
    "# Make sure the training directory exists\n",
    "if not os.path.exists(training_dir):\n",
    "    os.makedirs(training_dir)\n",
    "\n",
    "# Function to download an image from a URL and save it to a directory\n",
    "def download_image(url, save_path):\n",
    "    response = requests.get(url, stream=True)\n",
    "    if response.status_code == 200:\n",
    "        with open(save_path, 'wb') as f:\n",
    "            response.raw.decode_content = True\n",
    "            shutil.copyfileobj(response.raw, f)\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"Failed to download image from {url}\")\n",
    "        return False\n",
    "\n",
    "for index, row in top20_instances_df.iterrows():\n",
    "    file_name = row['image_paths']\n",
    "    save_path = os.path.join(training_dir, os.path.basename(file_name))\n",
    "    if os.path.exists(os.path.join(dataset_dir, file_name)):\n",
    "        shutil.copy(os.path.join(dataset_dir, file_name), save_path)\n",
    "    elif not os.path.exists(save_path):  # Check if file already exists in the target directory\n",
    "        url = website_url + file_name\n",
    "        if download_image(url, save_path):\n",
    "            print(f\"Downloaded {file_name} from {url}\")\n",
    "        else:\n",
    "            print(f\"Failed to find {file_name} in dataset_dir and download from {url}\")\n",
    "    else:\n",
    "        print(f\"{file_name} already exists in {training_dir}, skipping download.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading the Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_dir = './testing20_set'\n",
    "\n",
    "# Make sure the testing directory exists\n",
    "if not os.path.exists(testing_dir):\n",
    "    os.makedirs(testing_dir)\n",
    "\n",
    "for index, row in test_df.iterrows():\n",
    "    file_name = row['image_paths']\n",
    "    \n",
    "    # Check if the file ends with \".wmv\", if so, skip it\n",
    "    if file_name.endswith('.WMV'):\n",
    "        print(f\"Skipping {file_name} as it has the .wmv extension\")\n",
    "        continue\n",
    "    \n",
    "    save_path = os.path.join(testing_dir, os.path.basename(file_name))\n",
    "    if os.path.exists(os.path.join(dataset_dir, file_name)):\n",
    "        shutil.copy(os.path.join(dataset_dir, file_name), save_path)\n",
    "    elif not os.path.exists(save_path):  # Check if file already exists in the target directory\n",
    "        url = website_url + file_name\n",
    "        if download_image(url, save_path):\n",
    "            print(f\"Downloaded {file_name} from {url}\")\n",
    "        else:\n",
    "            print(f\"Failed to find {file_name} in dataset_dir and download from {url}\")\n",
    "    else:\n",
    "        print(f\"{file_name} already exists in {testing_dir}, skipping download. It was downloaded previously.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the size of the dataset\n",
    "print('Number of files in the training set: ', len(os.listdir('./training20_set')))\n",
    "print('Number of files in the test set: ', len(os.listdir('./testing20_set')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert an image file to a tensor\n",
    "def image_to_tensor(image_file):\n",
    "    image = Image.open(image_file)\n",
    "    image = Resize((224, 224))(image)\n",
    "    return ToTensor()(image)\n",
    "\n",
    "#calculate the weights\n",
    "def get_weight(class_num, label_count):\n",
    "    weights = 1 / np.log(label_count)\n",
    "    weights = class_num * weights/np.sum(weights)\n",
    "    return weights\n",
    "\n",
    "def add_class_weights(input_data):\n",
    "    #get the number of labels\n",
    "    result_data = input_data\n",
    "    label_num = len(result_data['labels'].unique())\n",
    "    \n",
    "    #Create a Pandas dataframe for weight caculation\n",
    "    value = result_data.value_counts('labels').tolist()\n",
    "    value_df = pd.DataFrame({'labels': result_data.value_counts('labels').index.tolist(), 'counts':result_data.value_counts('labels').tolist()})\n",
    "    \n",
    "    base = 2\n",
    "    value_df['counts'] = get_weight(label_num, base*value_df['counts'])\n",
    "    # value_df\n",
    "    list = value_df.set_index('labels').T.to_dict('list')\n",
    "    \n",
    "    for index, row in result_data.iterrows():\n",
    "        result_data.loc[index, ('weights')] = list[result_data.loc[index, ('labels')]][0]\n",
    "    \n",
    "    return result_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preview the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the base paths\n",
    "test_df['image_paths'] = test_df['image_paths'].apply(os.path.basename)\n",
    "top20_instances_df['image_paths'] = top20_instances_df['image_paths'].apply(os.path.basename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the first 5 image paths and decoded labels for the training dataset\n",
    "for index, row in top20_instances_df.head(5).iterrows():\n",
    "    image = row['image_paths']\n",
    "    label = row['base_label']\n",
    "    print(\"Image:\", image)\n",
    "    print(\"Label:\", encoder.inverse_transform([label])[0])\n",
    "    print()\n",
    "\n",
    "# display the first 9 images and their labels\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i, (index, row) in enumerate(top20_instances_df.head(9).iterrows()):\n",
    "    image_path = os.path.join(training_dir, row['image_paths'])  # Append training_dir to the beginning of the path\n",
    "    label = row['base_label']\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    \n",
    "    # Open the image file\n",
    "    with Image.open(image_path) as img:\n",
    "        plt.imshow(img)\n",
    "    \n",
    "    plt.title(encoder.inverse_transform([label])[0])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the first 5 image paths and decoded labels for the test dataset\n",
    "for index, row in test_df.head(5).iterrows():\n",
    "    image = row['image_paths']\n",
    "    label = row['base_label']\n",
    "    print(\"Image:\", image)\n",
    "    print(\"Label:\", encoder.inverse_transform([label])[0])\n",
    "    print()\n",
    "\n",
    "# display the first 9 images and their labels\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i, (index, row) in enumerate(test_df.head(9).iterrows()):\n",
    "    image_file_name = os.path.basename(row['image_paths'])  \n",
    "    image_path = os.path.join(test_dir, image_file_name)  \n",
    "    label = row['base_label']\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    \n",
    "    # Open the image file\n",
    "    with Image.open(image_path) as img:\n",
    "        plt.imshow(img)\n",
    "    \n",
    "    plt.title(encoder.inverse_transform([label])[0])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert column into strings\n",
    "top20_instances_df[\"image_paths\"] = top20_instances_df[\"image_paths\"].astype(str)\n",
    "top20_instances_df[\"base_label\"] = top20_instances_df[\"base_label\"].astype(str)\n",
    "\n",
    "train_df = top20_instances_df.copy()\n",
    "test_df[\"image_paths\"] = test_df[\"image_paths\"].astype(str)\n",
    "test_df[\"base_label\"] = test_df[\"base_label\"].astype(str)\n",
    "\n",
    "# train_df, test_df = train_test_split(test_df, test_size=0.2, random_state=42)\n",
    "test_df, eval_df = train_test_split(test_df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the image data generator for the training set\n",
    "imageTrain_data = ImageDataGenerator(\n",
    "    rescale = 1./255.,\n",
    "    rotation_range = 60,\n",
    "    shear_range = 0.3,\n",
    "    zoom_range = 0.5,\n",
    "    width_shift_range = 0.3,\n",
    "    height_shift_range = 0.3,\n",
    "    fill_mode=\"nearest\",\n",
    ")\n",
    "\n",
    "train_generator = imageTrain_data.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    directory=train_dir,\n",
    "    target_size = (img_height, img_width),\n",
    "    batch_size = batch_size,\n",
    "    x_col = \"image_paths\",\n",
    "    y_col = \"base_label\",\n",
    "    class_mode=\"categorical\",\n",
    ")\n",
    "\n",
    "\n",
    "# Create the image data generator for the evaluation set\n",
    "imageEval_data = ImageDataGenerator(rescale = 1./255.)\n",
    "\n",
    "eval_generator = imageEval_data.flow_from_dataframe(\n",
    "    dataframe=eval_df,\n",
    "    directory=test_dir,\n",
    "    target_size = (img_height, img_width),\n",
    "    batch_size = batch_size,\n",
    "    x_col = \"image_paths\",\n",
    "    y_col = \"base_label\",\n",
    "    class_mode=\"categorical\",\n",
    ")\n",
    "\n",
    "\n",
    "# Create the image data generator for the test set\n",
    "imageTest_data = ImageDataGenerator(rescale = 1./255.)\n",
    "\n",
    "test_generator = imageTest_data.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    directory=test_dir,\n",
    "    target_size = (img_height, img_width),\n",
    "    batch_size = batch_size,\n",
    "    x_col = \"image_paths\",\n",
    "    y_col = \"base_label\",\n",
    "    class_mode=\"categorical\",\n",
    ")\n",
    "\n",
    "#Display example of image augmentation\n",
    "sample_dataframe = test_df.sample(n=1).reset_index(drop=True)\n",
    "sample_generator = imageTrain_data.flow_from_dataframe(\n",
    "    dataframe=sample_dataframe,\n",
    "    directory=test_dir,\n",
    "    target_size = (img_height, img_width),\n",
    "    batch_size = batch_size,\n",
    "    x_col = \"image_paths\",\n",
    "    y_col = \"base_label\",\n",
    "    class_mode=\"categorical\",\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "for i in range (0, 15):\n",
    "  ax = plt.subplot(5, 3, i + 1)\n",
    "  for X_column, Y_column in sample_generator:\n",
    "    plt.imshow(X_column[0])\n",
    "    break\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels = pd.concat([train_df['base_label'], eval_df['base_label'], test_df['base_label']])\n",
    "# num_labels = all_labels.nunique() - 1\n",
    "num_labels = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if CUDA is available and set the device accordingly\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# # Compute class weights\n",
    "# class_counts = np.bincount(train_labels)\n",
    "# class_weights = 1. / class_counts\n",
    "# class_weights = class_weights / np.sum(class_weights) * len(class_counts)\n",
    "# class_weights = torch.FloatTensor(class_weights).to(device)\n",
    "    \n",
    "class ViTForImageClassification(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        # self.vit = ViTModel(config, add_pooling_layer=False)\n",
    "        # self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
    "        self.vit = ViTModel(config, add_pooling_layer=False).to(device)                # Move model to Nvidia card\n",
    "        self.classifier = nn.Linear(config.hidden_size, config.num_labels).to(device)  # Move model to Nvidia card\n",
    "\n",
    "    def forward(self, pixel_values, labels):\n",
    "        outputs = self.vit(pixel_values=pixel_values)\n",
    "        logits = self.classifier(outputs.last_hidden_state[:, 0])\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            # loss_fct = nn.CrossEntropyLoss(weight=class_weights)\n",
    "            loss = loss_fct(logits, labels)\n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )\n",
    "    \n",
    "\n",
    "# compute accuracy\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    if isinstance(labels, int):\n",
    "        labels = [labels]\n",
    "    accuracy = load_metric(\"accuracy\").compute(predictions=predictions, references=labels)\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    return accuracy\n",
    "    \n",
    "        \n",
    "# create feature extractor to tokenize data\n",
    "feature_extractor = ViTImageProcessor(\n",
    "    image_size=224,\n",
    "    do_resize=True,\n",
    "    do_normalize=True,\n",
    "    do_rescale=False,\n",
    "    image_mean=[0.5, 0.5, 0.5],\n",
    "    image_std=[0.5, 0.5, 0.5],\n",
    ")\n",
    "\n",
    "\n",
    "# Define a function to load and preprocess the images\n",
    "def load_and_preprocess_images(example, directory):\n",
    "    # Load the image from the file\n",
    "    image = Image.open(directory + example['image_paths'])\n",
    "    image = np.array(image, dtype=np.uint8)\n",
    "    image = np.moveaxis(image, source=-1, destination=0)\n",
    "    # Preprocess the image\n",
    "    inputs = feature_extractor(images=[image])\n",
    "    pixel_values = torch.tensor(inputs['pixel_values'][0], dtype=torch.float32).to(device)  # convert to tensor and move to device\n",
    "    label = int(example['labels'])\n",
    "    return {'pixel_values': pixel_values, 'labels': label}\n",
    "\n",
    "\n",
    "# define a custom data collator\n",
    "def data_collator(features):\n",
    "    pixel_values = [torch.tensor(feature['pixel_values'], dtype=torch.float32).to(device) for feature in features]  # Move to device\n",
    "    labels = [feature['labels'] for feature in features]\n",
    "    pixel_values = torch.stack(pixel_values)\n",
    "    return {'pixel_values': pixel_values, 'labels': torch.tensor(labels).to(device)}  # Move to device\n",
    "\n",
    "\n",
    "# Define the features of the dataset\n",
    "features = Features({\n",
    "    'labels': ClassLabel(num_classes=num_labels),\n",
    "    'img': Array3D(dtype=\"int64\", shape=(3, 32, 32)),\n",
    "    'pixel_values': Array3D(dtype=\"float32\", shape=(3, 224, 224)),\n",
    "})\n",
    "\n",
    "# Generate lists of image paths and labels for training dataset\n",
    "train_image_paths = train_df[\"image_paths\"].tolist()\n",
    "train_labels = train_df[\"base_label\"].tolist()\n",
    "\n",
    "# Create a dictionary with the image paths and labels\n",
    "train_dict = {'image_paths': train_image_paths, 'labels': train_labels}\n",
    "\n",
    "# Create the dataset\n",
    "train_dataset = Dataset.from_dict(train_dict)\n",
    "\n",
    "# Apply the function to the dataset\n",
    "# train_dataset = train_dataset.map(lambda example: load_and_preprocess_images(example, 'testing20_set/'))\n",
    "train_dataset = train_dataset.remove_columns(['image_paths'])\n",
    "\n",
    "\n",
    "# Repeat the same process for the evaluation and test datasets\n",
    "eval_image_paths = eval_df[\"image_paths\"].tolist()\n",
    "eval_labels = eval_df[\"base_label\"].tolist()\n",
    "eval_dict = {'image_paths': eval_image_paths, 'labels': eval_labels}\n",
    "eval_dataset = Dataset.from_dict(eval_dict)\n",
    "# eval_dataset = eval_dataset.map(lambda example: load_and_preprocess_images(example, 'testing20_set/'))\n",
    "eval_dataset = eval_dataset.remove_columns(['image_paths'])\n",
    "\n",
    "\n",
    "test_image_paths = test_df[\"image_paths\"].tolist()\n",
    "test_labels = test_df[\"base_label\"].tolist()\n",
    "test_dict = {'image_paths': test_image_paths, 'labels': test_labels}\n",
    "test_dataset = Dataset.from_dict(test_dict)\n",
    "# test_dataset = test_dataset.map(lambda example: load_and_preprocess_images(example, 'testing20_set/'))\n",
    "test_dataset = test_dataset.remove_columns(['image_paths'])\n",
    "\n",
    "\n",
    "# Load the pre-trained model\n",
    "pretrained_model = ViTModel.from_pretrained('google/vit-base-patch16-224')\n",
    "\n",
    "# Define your custom model\n",
    "config = pretrained_model.config\n",
    "config.num_labels = num_labels\n",
    "model = ViTForImageClassification(config)\n",
    "\n",
    "# Copy the pre-trained weights to your custom model\n",
    "model.vit = pretrained_model\n",
    "\n",
    "early_stopping_callback = EarlyStoppingCallback(\n",
    "    early_stopping_patience=10,  # Number of evaluations with no improvement after which training will be stopped.\n",
    "    early_stopping_threshold=0.0  # Threshold for measuring the new optimum, to only focus on significant changes.\n",
    ")\n",
    "\n",
    "# create the training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    num_train_epochs=20,              # total number of training epochs\n",
    "    per_device_train_batch_size=16,  # batch size per device during training\n",
    "    per_device_eval_batch_size=16,   # batch size for evaluation\n",
    "    warmup_steps=75,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.018,               # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    logging_steps=5,\n",
    "    logging_first_step=True,\n",
    "    logging_strategy='steps',\n",
    "    evaluation_strategy='epoch',\n",
    "    eval_steps=10,  \n",
    "    save_strategy='epoch',\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='accuracy',\n",
    "    greater_is_better=True,\n",
    "    learning_rate=5e-5,\n",
    "    gradient_accumulation_steps=1,      # prevents vanishing/exploding gradients\n",
    "    max_grad_norm=1.0,                  # prevents vanishing/exploding gradients\n",
    "    # fp16=True                     # mixed precision training; enable if using nVidia graphics cards\n",
    ")\n",
    "\n",
    "class CustomTrainer(Trainer):\n",
    "    def get_train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.args.train_batch_size, shuffle=True, collate_fn=self.data_collator)\n",
    "    \n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        # Move inputs to device\n",
    "        for key, value in inputs.items():\n",
    "            inputs[key] = value.to(device)\n",
    "\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        labels = inputs[\"labels\"]  # Get labels from inputs\n",
    "\n",
    "        loss = torch.nn.functional.cross_entropy(logits, labels)\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "        \n",
    "mainTrainer = CustomTrainer (\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[early_stopping_callback]  # Add the early stopping callback\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%\n",
    "mainTrainer.train()\n",
    "mainTrainer.save_model('./saved_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Testing\n",
    "\n",
    "Download the model from HuggingFace under the directory ./saved_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from safetensors import safe_open\n",
    "\n",
    "tensors = {}\n",
    "with safe_open(\"./saved_model1 - best/model.safetensors\", framework=\"pt\", device='cpu') as f:\n",
    "    for k in f.keys():\n",
    "        tensors[k] = f.get_tensor(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to load and preprocess the images for testing\n",
    "def load_and_preprocess_images(example, directory):\n",
    "    image = Image.open(directory + example['image_paths'])\n",
    "    image = np.array(image, dtype=np.uint8)\n",
    "    image = np.moveaxis(image, source=-1, destination=0)\n",
    "    inputs = feature_extractor(images=[image])\n",
    "    pixel_values = torch.tensor(inputs['pixel_values'][0], dtype=torch.float32).to(device)\n",
    "    label = int(example['labels'])\n",
    "    return {'pixel_values': pixel_values, 'labels': label}\n",
    "\n",
    "# Apply the function to the test dataset\n",
    "test_dataset = Dataset.from_dict(test_dict)\n",
    "test_dataset = test_dataset.map(lambda example: load_and_preprocess_images(example, 'testing20_set/'))\n",
    "test_dataset = test_dataset.remove_columns(['image_paths'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained model\n",
    "pretrained_model = ViTModel.from_pretrained('google/vit-base-patch16-224')\n",
    "\n",
    "# Define your custom model\n",
    "config = pretrained_model.config\n",
    "config.num_labels = num_labels\n",
    "model = ViTForImageClassification(config)\n",
    "\n",
    "# Copy the pre-trained weights to your custom model\n",
    "model.vit = pretrained_model\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.load_state_dict(tensors)\n",
    "model.eval()\n",
    "\n",
    "# Create a DataLoader for the test dataset\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=data_collator)\n",
    "\n",
    "# Lists to store predictions and true labels\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "all_losses = []\n",
    "\n",
    "# Iterate through the test dataset\n",
    "for batch in test_dataloader:\n",
    "    with torch.no_grad():\n",
    "        # Forward pass\n",
    "        inputs = batch['pixel_values']\n",
    "        labels = batch['labels']\n",
    "        outputs = model(pixel_values=inputs, labels=labels)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        # Convert logits to predictions\n",
    "        predictions = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "\n",
    "        loss = outputs.loss.item()\n",
    "\n",
    "        # Append predictions and true labels to lists\n",
    "        all_predictions.extend(predictions)\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_losses.append(loss)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "all_predictions = np.array(all_predictions)\n",
    "all_labels = np.array(all_labels)\n",
    "all_losses = np.array(all_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy and other metrics\n",
    "accuracy = accuracy_score(all_labels, all_predictions)\n",
    "precision, recall, fscore, _ = precision_recall_fscore_support(all_labels, all_predictions, average='weighted')\n",
    "classification_report_str = classification_report(all_labels, all_predictions)\n",
    "\n",
    "# Print or use the metrics as needed\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {fscore}\")\n",
    "print(\"Classification Report:\\n\", tabulate([[''] + classification_report_str.split('\\n')[0].split()] + [line.split() for line in classification_report_str.split('\\n')[2:-5]], headers='firstrow', tablefmt='grid'))\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(all_losses, label='Test Loss')\n",
    "plt.xlabel('Batch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(all_labels, all_predictions, 'bo', markersize=3)\n",
    "plt.xlabel('True Labels')\n",
    "plt.ylabel('Predicted Labels')\n",
    "plt.title('True vs Predicted Labels')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
