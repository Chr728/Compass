{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pill Identifier Machine Learning Model and API\n",
    "All pills and tablets have a unique combination of features that allow them to be identified. \n",
    "These features are its color, its shape, and imprints made in front and/or at the back of the drug.\n",
    "The model aims to predict the name of an unknown pill/tablet based on these features.\n",
    "\n",
    "This model will utilize `google/vit-base-patch16-224` for image classification.\n",
    "\n",
    "The dataset is from the U.S. Department of Health's Computational Photography Project for Pill Identification (C3PI)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e7SczRM2XJyN"
   },
   "source": [
    "# Imports, Declarations, and Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T22:36:43.358190Z",
     "start_time": "2024-01-04T22:36:38.947503Z"
    },
    "id": "YSVBXMIEXQLa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\imran\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\imran\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import torch\n",
    "import os\n",
    "import requests\n",
    "from PIL import Image\n",
    "from torchvision.transforms import ToTensor\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt     # to plot charts\n",
    "import numpy as np\n",
    "import pandas as pd                 # for data manipulation\n",
    "import cv2                          # for image processing\n",
    "from io import BytesIO\n",
    "from tabulate import tabulate       # to print pretty tables\n",
    "\n",
    "# sklearn imports for metrics and dataset splitting\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# keras imports for image preprocessing\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# huggingface imports for model building \n",
    "import torch.nn as nn\n",
    "from transformers import ViTModel, ViTForImageClassification, TrainingArguments, Trainer, \\\n",
    "  default_data_collator, EarlyStoppingCallback, ViTConfig, AutoImageProcessor, ViTImageProcessor \n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "\n",
    "# keras imports for early stoppage and model checkpointing\n",
    "from torchvision.transforms import ToTensor, Resize\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.io import read_image\n",
    "\n",
    "from datasets import load_dataset, load_metric, Features, ClassLabel, Array3D, Dataset\n",
    "import datasets\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_URL = 'https://data.lhncbc.nlm.nih.gov/public/Pills/'\n",
    "directory = \"dataset\"\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qeJN4BQ3dF0H"
   },
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T22:36:45.362505Z",
     "start_time": "2024-01-04T22:36:45.356006Z"
    },
    "id": "WC-oRwKNdOqu"
   },
   "outputs": [],
   "source": [
    "# Function to convert an image file to a tensor\n",
    "def image_to_tensor(image_file):\n",
    "    image = Image.open(image_file)\n",
    "    image = Resize((224, 224))(image)\n",
    "    return ToTensor()(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "54DLyRiiXkpH"
   },
   "source": [
    "# Data Acquisition\n",
    "Retrieves the images from our dataset and stores them in memory.\n",
    "Corresponding labels are retrieved, as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T22:36:46.590066Z",
     "start_time": "2024-01-04T22:36:46.524940Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zg9m_GC-zWMu",
    "outputId": "9cb4cc80-cc39-4af9-8cde-1902baa34c7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels: 2112\n",
      "Image: b'00093-0311-01_RXNAVIMAGE10_26211358.jpg'\n",
      "Label: Loperamide Hydrochloride 2 MG Oral Capsule\n",
      "\n",
      "Image: b'00093-3165-01_RXNAVIMAGE10_36231B28.jpg'\n",
      "Label: Minocycline 50 MG Oral Capsule\n",
      "\n",
      "Image: b'00093-0810-01_RXNAVIMAGE10_24231228.jpg'\n",
      "Label: Nortriptyline 10 MG Oral Capsule\n",
      "\n",
      "Image: b'00093-0811-01_RXNAVIMAGE10_20231018.jpg'\n",
      "Label: Nortriptyline 25 MG Oral Capsule\n",
      "\n",
      "Image: b'00093-0812-01_RXNAVIMAGE10_2D2316D8.jpg'\n",
      "Label: Nortriptyline 50 MG Oral Capsule\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# read the csv file with labels\n",
    "csv_file = \"table.csv\"\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "df[\"encoded_label\"] = label_encoder.fit_transform(df[\"name\"])\n",
    "\n",
    "# create a dataset from the dataframe\n",
    "image_paths = df[\"rxnavImageFileName\"].values\n",
    "labels = df[\"encoded_label\"].values\n",
    "num_labels = len(df[\"encoded_label\"].unique())\n",
    "print(\"Number of labels:\", num_labels)\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((image_paths, labels))\n",
    "dataset_df = pd.DataFrame(list(dataset.as_numpy_iterator()), columns=['image_paths', 'labels'])\n",
    "\n",
    "# print the first 5 image paths and decoded labels\n",
    "for image, label in dataset.take(5):\n",
    "  print(\"Image:\", image.numpy())\n",
    "  print(\"Label:\", label_encoder.inverse_transform([label.numpy()])[0])\n",
    "  print()\n",
    "\n",
    "# np.save('encoder/encoder.npy', label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T22:36:47.545335Z",
     "start_time": "2024-01-04T22:36:47.513945Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_images(path, label):\n",
    "  image = tf.io.read_file(directory + '/' + path)\n",
    "  image = tf.image.decode_jpeg(image, channels=3)\n",
    "  image = tf.image.resize(image, [256, 256])\n",
    "  image /= 255.0 \n",
    "  return image, label\n",
    "\n",
    "dataset = dataset.map(load_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-04T22:36:48.374189Z"
    },
    "is_executing": true
   },
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "{{function_node __wrapped__IteratorGetNext_output_types_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} NewRandomAccessFile failed to Create/Open: dataset/00093-0311-01_RXNAVIMAGE10_26211358.jpg : The system cannot find the path specified.\r\n; No such process\n\t [[{{node ReadFile}}]] [Op:IteratorGetNext] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# display the first 9 images and their labels\u001b[39;00m\n\u001b[0;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m10\u001b[39m))\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m9\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m  \u001b[49m\u001b[43max\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubplot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m  \u001b[49m\u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\imran\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:810\u001b[0m, in \u001b[0;36mOwnedIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    808\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    809\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 810\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    811\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOutOfRangeError:\n\u001b[0;32m    812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\imran\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:773\u001b[0m, in \u001b[0;36mOwnedIterator._next_internal\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    770\u001b[0m \u001b[38;5;66;03m# TODO(b/77291417): This runs in sync mode as iterators use an error status\u001b[39;00m\n\u001b[0;32m    771\u001b[0m \u001b[38;5;66;03m# to communicate that there is no more data to iterate over.\u001b[39;00m\n\u001b[0;32m    772\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecution_mode(context\u001b[38;5;241m.\u001b[39mSYNC):\n\u001b[1;32m--> 773\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator_get_next\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    774\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator_resource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    775\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    776\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_shapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    778\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    779\u001b[0m     \u001b[38;5;66;03m# Fast path for the case `self._structure` is not a nested structure.\u001b[39;00m\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_element_spec\u001b[38;5;241m.\u001b[39m_from_compatible_tensor_list(ret)  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\imran\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:3029\u001b[0m, in \u001b[0;36miterator_get_next\u001b[1;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[0;32m   3027\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m   3028\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 3029\u001b[0m   \u001b[43m_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from_not_ok_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3030\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_FallbackException:\n\u001b[0;32m   3031\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\imran\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:5883\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   5881\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[0;32m   5882\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m-> 5883\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mNotFoundError\u001b[0m: {{function_node __wrapped__IteratorGetNext_output_types_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} NewRandomAccessFile failed to Create/Open: dataset/00093-0311-01_RXNAVIMAGE10_26211358.jpg : The system cannot find the path specified.\r\n; No such process\n\t [[{{node ReadFile}}]] [Op:IteratorGetNext] name: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display the first 9 images and their labels\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i, (image, label) in enumerate(dataset.take(9)):\n",
    "  ax = plt.subplot(3, 3, i + 1)\n",
    "  plt.imshow(image)\n",
    "  plt.title(label_encoder.inverse_transform([label.numpy()])[0])\n",
    "  plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add datapoints to dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing labels: 0\n",
      "Total number of labels after removing missing labels:  133774\n",
      "2866    434\n",
      "1659    413\n",
      "175     392\n",
      "2539    379\n",
      "1158    377\n",
      "       ... \n",
      "1635     13\n",
      "1452     13\n",
      "899      13\n",
      "1517     13\n",
      "1453     13\n",
      "Name: encoded_label, Length: 3010, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1IAAAIjCAYAAAAJLyrXAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABXnElEQVR4nO3dfXxMZ/7/8ffkliQigiRShKIq7kvLtFrWTVBVlm5btYTa6mq07qqabhG0Ddq6rdK7RXdrdXV7R93F/VKUVEpRW6poibRuEpFKJpnz+8Mv8zVNwpxIMhNez8cjj80555pzfc7Jtd2+9zrnGothGIYAAAAAAC7zcncBAAAAAFDeEKQAAAAAwCSCFAAAAACYRJACAAAAAJMIUgAAAABgEkEKAAAAAEwiSAEAAACASQQpAAAAADCJIAUAAAAAJhGkAOAmkJCQIIvFUiZ9dejQQR06dHBsb9q0SRaLRR999FGZ9D9o0CDVqVOnTPoqrszMTP3lL39RRESELBaLRo4cWSb9Dho0SEFBQSV6zt//vQHgZkGQAoByZtGiRbJYLI6fChUqKDIyUl27dtWcOXN04cKFEunn5MmTSkhIUEpKSomcryR5cm2ueOWVV7Ro0SINGzZM//jHPzRgwIAi29apU0cPPPBAGVYHAHCFj7sLAAAUz+TJk1W3bl3ZbDalpqZq06ZNGjlypGbMmKHPP/9czZo1c7R98cUX9fzzz5s6/8mTJzVp0iTVqVNHLVq0cPlza9euNdVPcVyttnfeeUd2u73Ua7geGzZsUNu2bTVx4kR3lwIAKCaCFACUU927d1fr1q0d2/Hx8dqwYYMeeOABPfjggzp48KAqVqwoSfLx8ZGPT+n+Iz8rK0sBAQHy8/Mr1X6uxdfX1639uyItLU3R0dHuLgMAcB14tA8AbiAdO3bU+PHjdezYMf3zn/907C/sHamkpCS1a9dOISEhCgoKUsOGDfXCCy9Iuvxe05133ilJGjx4sOMxwkWLFkm6/F5MkyZNlJycrPvuu08BAQGOzxb1zkxeXp5eeOEFRUREKDAwUA8++KBOnDjh1KZOnToaNGhQgc9eec5r1VbYO1IXL17UmDFjVKtWLfn7+6thw4Z67bXXZBiGUzuLxaLhw4fr008/VZMmTeTv76/GjRtr9erVhd/w30lLS9OQIUMUHh6uChUqqHnz5lq8eLHjeP77YkePHtUXX3zhqP3HH3906fxF+e9//6s//elPql27tvz9/VWrVi2NGjVKv/32W6Htf/jhB3Xt2lWBgYGKjIzU5MmTC9wLu92uWbNmqXHjxqpQoYLCw8P15JNP6ty5c9esZ+7cuWrcuLECAgJUpUoVtW7dWkuWLLmuawQAT8OMFADcYAYMGKAXXnhBa9eu1RNPPFFom/379+uBBx5Qs2bNNHnyZPn7++vw4cPatm2bJKlRo0aaPHmyJkyYoKFDh+ree++VJN19992Oc5w5c0bdu3fXo48+qj//+c8KDw+/al0vv/yyLBaLxo0bp7S0NM2aNUudO3dWSkqKY+bMFa7UdiXDMPTggw9q48aNGjJkiFq0aKE1a9Zo7Nix+vnnnzVz5kyn9lu3btXHH3+sp556SpUqVdKcOXPUt29fHT9+XFWrVi2yrt9++00dOnTQ4cOHNXz4cNWtW1fLli3ToEGDdP78eY0YMUKNGjXSP/7xD40aNUo1a9bUmDFjJEnVq1d3+foLs2zZMmVlZWnYsGGqWrWqvvrqK82dO1c//fSTli1b5tQ2Ly9P3bp1U9u2bTV9+nStXr1aEydOVG5uriZPnuxo9+STT2rRokUaPHiwnnnmGR09elRvvPGG9uzZo23bthU58/fOO+/omWee0UMPPaQRI0bo0qVL2rt3r3bu3KnHHnvsuq4TADyKAQAoVxYuXGhIMnbt2lVkm8qVKxstW7Z0bE+cONG48h/5M2fONCQZv/zyS5Hn2LVrlyHJWLhwYYFj7du3NyQZCxYsKPRY+/btHdsbN240JBm33HKLkZGR4dj/73//25BkzJ4927EvKirKiI2NveY5r1ZbbGysERUV5dj+9NNPDUnGSy+95NTuoYceMiwWi3H48GHHPkmGn5+f075vvvnGkGTMnTu3QF9XmjVrliHJ+Oc//+nYl5OTY1itViMoKMjp2qOioowePXpc9Xxm2mZlZRXYl5iYaFgsFuPYsWOOfbGxsYYk4+mnn3bss9vtRo8ePQw/Pz/HePjvf/9rSDI++OADp3OuXr26wP7f/2169eplNG7c2KVrA4DyjEf7AOAGFBQUdNXV+0JCQiRJn332WbEXZvD399fgwYNdbj9w4EBVqlTJsf3QQw+pRo0aWrlyZbH6d9XKlSvl7e2tZ555xmn/mDFjZBiGVq1a5bS/c+fOqlevnmO7WbNmCg4O1g8//HDNfiIiItSvXz/HPl9fXz3zzDPKzMzU5s2bS+BqCnfljN7Fixf166+/6u6775ZhGNqzZ0+B9sOHD3f8nv84Y05OjtatWyfp8gxX5cqV1aVLF/3666+On1atWikoKEgbN24sspaQkBD99NNP2rVrVwleIQB4HoIUANyAMjMznULL7z3yyCO655579Je//EXh4eF69NFH9e9//9tUqLrllltMLSzRoEEDp22LxaL69etf9/tB13Ls2DFFRkYWuB+NGjVyHL9S7dq1C5yjSpUq13w36NixY2rQoIG8vJz/p7WofkrS8ePHNWjQIIWGhiooKEjVq1dX+/btJUnp6elObb28vHTrrbc67bvtttskyfG3+P7775Wenq6wsDBVr17d6SczM1NpaWlF1jJu3DgFBQXprrvuUoMGDRQXF+d4ZBQAbiS8IwUAN5iffvpJ6enpql+/fpFtKlasqC1btmjjxo364osvtHr1an344Yfq2LGj1q5dK29v72v2Y+a9JlcV9aXBeXl5LtVUEorqx/jdYgyeIi8vT126dNHZs2c1btw43X777QoMDNTPP/+sQYMGFWvG0W63KywsTB988EGhx6/2TlejRo106NAhrVixQqtXr9Z//vMfvfnmm5owYYImTZpkuhYA8FQEKQC4wfzjH/+QJHXt2vWq7by8vNSpUyd16tRJM2bM0CuvvKK//e1v2rhxozp37lxkqCmu77//3mnbMAwdPnzY6fuuqlSpovPnzxf47LFjx5xmUczUFhUVpXXr1unChQtOs1Lfffed43hJiIqK0t69e2W3251mpUq6n9/bt2+f/ve//2nx4sUaOHCgY39SUlKh7e12u3744QfHLJQk/e9//5Mkx2qH9erV07p163TPPfcUKzAHBgbqkUce0SOPPKKcnBz16dNHL7/8suLj41WhQgXT5wMAT8SjfQBwA9mwYYOmTJmiunXrqn///kW2O3v2bIF9+V9sm52dLenyvwxLKjTYFMf777/v9N7WRx99pFOnTql79+6OffXq1dOOHTuUk5Pj2LdixYoCy6Sbqe3+++9XXl6e3njjDaf9M2fOlMVicer/etx///1KTU3Vhx9+6NiXm5uruXPnKigoyPGoXUnLn0G7csbMMAzNnj27yM9ceS8Mw9Abb7whX19fderUSZL08MMPKy8vT1OmTCnw2dzc3Kve9zNnzjht+/n5KTo6WoZhyGazuXRNAFAeMCMFAOXUqlWr9N133yk3N1enT5/Whg0blJSUpKioKH3++edX/X/+J0+erC1btqhHjx6KiopSWlqa3nzzTdWsWVPt2rWTdDnUhISEaMGCBapUqZICAwPVpk0b1a1bt1j1hoaGql27dho8eLBOnz6tWbNmqX79+k5LtP/lL3/RRx99pG7duunhhx/WkSNH9M9//tNp8QeztfXs2VN/+MMf9Le//U0//vijmjdvrrVr1+qzzz7TyJEjC5y7uIYOHaq33npLgwYNUnJysurUqaOPPvpI27Zt06xZs676ztq1HD58WC+99FKB/S1btlRMTIzq1aunZ599Vj///LOCg4P1n//8p8h3uipUqKDVq1crNjZWbdq00apVq/TFF1/ohRdecDyy1759ez355JNKTExUSkqKYmJi5Ovrq++//17Lli3T7Nmz9dBDDxV6/piYGEVEROiee+5ReHi4Dh48qDfeeEM9evS4rnsAAB7HfQsGAgCKI3/58/wfPz8/IyIiwujSpYsxe/Zsp2W28/1++fP169cbvXr1MiIjIw0/Pz8jMjLS6Nevn/G///3P6XOfffaZER0dbfj4+DgtN96+ffsil7guavnzf/3rX0Z8fLwRFhZmVKxY0ejRo4fT0tz5Xn/9deOWW24x/P39jXvuucfYvXt3gXNerbbfL39uGIZx4cIFY9SoUUZkZKTh6+trNGjQwHj11VcNu93u1E6SERcXV6CmopZl/73Tp08bgwcPNqpVq2b4+fkZTZs2LXSJdrPLn1/5977yZ8iQIYZhGMaBAweMzp07G0FBQUa1atWMJ554wrFs+5X9x8bGGoGBgcaRI0eMmJgYIyAgwAgPDzcmTpxo5OXlFej77bffNlq1amVUrFjRqFSpktG0aVPjueeeM06ePOlo8/u/zVtvvWXcd999RtWqVQ1/f3+jXr16xtixY4309HSXrhcAyguLYXjo27MAAAAA4KF4RwoAAAAATCJIAQAAAIBJBCkAAAAAMIkgBQAAAAAmEaQAAAAAwCSCFAAAAACYxBfySrLb7Tp58qQqVaoki8Xi7nIAAAAAuIlhGLpw4YIiIyPl5VX0vBNBStLJkydVq1Ytd5cBAAAAwEOcOHFCNWvWLPI4QUpSpUqVJF2+WcHBwS59xmazae3atYqJiZGvr29plgeYwtiEJ2N8wlMxNuHJGJ9lKyMjQ7Vq1XJkhKIQpCTH43zBwcGmglRAQICCg4MZ0PAojE14MsYnPBVjE56M8eke13rlh8UmAAAAAMAkghQAAAAAmESQAgAAAACTCFIAAAAAYBJBCgAAAABMIkgBAAAAgEkEKQAAAAAwiSAFAAAAACYRpAAAAADAJIIUAAAAAJhEkAIAAAAAkwhSAAAAAGASQQoAAAAATCJIAQAAAIBJBCkAAAAAMIkgBQAAAAAmEaQAAAAAwCSCFAAAAACYRJACAAAAAJMIUuVIwqYEJWxKcHcZAAAAwE2PIAUAAAAAJhGkAAAAAMAkghQAAAAAmESQAgAAAACTCFIAAAAAYBJBCgAAAABM8pggNXXqVFksFo0cOdKx79KlS4qLi1PVqlUVFBSkvn376vTp006fO378uHr06KGAgACFhYVp7Nixys3NLePqAQAAANxMPCJI7dq1S2+99ZaaNWvmtH/UqFFavny5li1bps2bN+vkyZPq06eP43heXp569OihnJwcffnll1q8eLEWLVqkCRMmlPUlAAAAALiJ+Li7gMzMTPXv31/vvPOOXnrpJcf+9PR0vffee1qyZIk6duwoSVq4cKEaNWqkHTt2qG3btlq7dq0OHDigdevWKTw8XC1atNCUKVM0btw4JSQkyM/Pr9A+s7OzlZ2d7djOyMiQJNlsNtlsNpfqzm/navuS4GV4lXmfKH/cMTYBVzE+4akYm/BkjM+y5ep9thiGYZRyLVcVGxur0NBQzZw5Ux06dFCLFi00a9YsbdiwQZ06ddK5c+cUEhLiaB8VFaWRI0dq1KhRmjBhgj7//HOlpKQ4jh89elS33nqrvv76a7Vs2bLQPhMSEjRp0qQC+5csWaKAgICSvkQAAAAA5URWVpYee+wxpaenKzg4uMh2bp2RWrp0qb7++mvt2rWrwLHU1FT5+fk5hShJCg8PV2pqqqNNeHh4geP5x4oSHx+v0aNHO7YzMjJUq1YtxcTEXPVmXclmsykpKUldunSRr6+vS5+5XolbEyVJ8e3iy6Q/lE/uGJuAqxif8FSMTXgyxmfZyn9a7VrcFqROnDihESNGKCkpSRUqVCjTvv39/eXv719gv6+vr+nBWZzPFJfdYnf0CVxLWY5NwCzGJzwVYxOejPFZNly9x25bbCI5OVlpaWm644475OPjIx8fH23evFlz5syRj4+PwsPDlZOTo/Pnzzt97vTp04qIiJAkRUREFFjFL387vw0AAAAAlDS3BalOnTpp3759SklJcfy0bt1a/fv3d/zu6+ur9evXOz5z6NAhHT9+XFarVZJktVq1b98+paWlOdokJSUpODhY0dHRZX5NAAAAAG4Obnu0r1KlSmrSpInTvsDAQFWtWtWxf8iQIRo9erRCQ0MVHBysp59+WlarVW3btpUkxcTEKDo6WgMGDND06dOVmpqqF198UXFxcYU+ugcAAAAAJcHty59fzcyZM+Xl5aW+ffsqOztbXbt21Ztvvuk47u3trRUrVmjYsGGyWq0KDAxUbGysJk+e7MaqAQAAANzoPCpIbdq0yWm7QoUKmjdvnubNm1fkZ6KiorRy5cpSrgwAAAAA/o/b3pECAAAAgPKKIAUAAAAAJhGkAAAAAMAkghQAAAAAmESQAgAAAACTCFIAAAAAYBJBCgAAAABMIkgBAAAAgEkEKQAAAAAwiSAFAAAAACYRpAAAAADAJIIUAAAAAJhEkAIAAAAAkwhSAAAAAGASQQoAAAAATCJIAQAAAIBJBCkAAAAAMIkgBQAAAAAmEaQAAAAAwCSCFAAAAACYRJACAAAAAJMIUgAAAABgEkEKAAAAAEwiSAEAAACASQQpAAAAADCJIAUAAAAAJhGkAAAAAMAkghQAAAAAmESQAgAAAACTCFIAAAAAYBJBCgAAAABMIkgBAAAAgEkEKQAAAAAwiSAFAAAAACYRpAAAAADAJIIUAAAAAJhEkAIAAAAAkwhSAAAAAGASQQoAAAAATCJIAQAAAIBJBCkAAAAAMIkgBQAAAAAmuTVIzZ8/X82aNVNwcLCCg4NltVq1atUqx/EOHTrIYrE4/fz1r391Osfx48fVo0cPBQQEKCwsTGPHjlVubm5ZXwoAAACAm4iPOzuvWbOmpk6dqgYNGsgwDC1evFi9evXSnj171LhxY0nSE088ocmTJzs+ExAQ4Pg9Ly9PPXr0UEREhL788kudOnVKAwcOlK+vr1555ZUyv54bWcKmhMv/2SHBrXUAAAAAnsCtQapnz55O2y+//LLmz5+vHTt2OIJUQECAIiIiCv382rVrdeDAAa1bt07h4eFq0aKFpkyZonHjxikhIUF+fn6lfg0AAAAAbj5uDVJXysvL07Jly3Tx4kVZrVbH/g8++ED//Oc/FRERoZ49e2r8+PGOWant27eradOmCg8Pd7Tv2rWrhg0bpv3796tly5aF9pWdna3s7GzHdkZGhiTJZrPJZrO5VG9+O1fblwQvw6vM+/SEvmGOO8Ym4CrGJzwVYxOejPFZtly9zxbDMIxSruWq9u3bJ6vVqkuXLikoKEhLlizR/fffL0l6++23FRUVpcjISO3du1fjxo3TXXfdpY8//liSNHToUB07dkxr1qxxnC8rK0uBgYFauXKlunfvXmifCQkJmjRpUoH9S5YscXp0EAAAAMDNJSsrS4899pjS09MVHBxcZDu3z0g1bNhQKSkpSk9P10cffaTY2Fht3rxZ0dHRGjp0qKNd06ZNVaNGDXXq1ElHjhxRvXr1it1nfHy8Ro8e7djOyMhQrVq1FBMTc9WbdSWbzaakpCR16dJFvr6+xa7FjMStiZKk+HbxZdKfp/QNc9wxNgFXMT7hqRib8GSMz7KV/7Tatbg9SPn5+al+/fqSpFatWmnXrl2aPXu23nrrrQJt27RpI0k6fPiw6tWrp4iICH311VdObU6fPi1JRb5XJUn+/v7y9/cvsN/X19f04CzOZ4rLbrE7+ixr7uwbxVOWYxMwi/EJT8XYhCdjfJYNV++xx32PlN1ud3p/6UopKSmSpBo1akiSrFar9u3bp7S0NEebpKQkBQcHKzo6utRrBQAAAHBzcuuMVHx8vLp3767atWvrwoULWrJkiTZt2qQ1a9boyJEjjvelqlatqr1792rUqFG677771KxZM0lSTEyMoqOjNWDAAE2fPl2pqal68cUXFRcXV+iMEwAAAACUBLcGqbS0NA0cOFCnTp1S5cqV1axZM61Zs0ZdunTRiRMntG7dOs2aNUsXL15UrVq11LdvX7344ouOz3t7e2vFihUaNmyYrFarAgMDFRsb6/S9UwAAAABQ0twapN57770ij9WqVUubN2++5jmioqK0cuXKkiwLAAAAAK7K496RAgAAAABPR5ACAAAAAJMIUgAAAABgEkEKAAAAAEwiSAEAAACASQQpAAAAADCJIAUAAAAAJhGkAAAAAMAkghQAAAAAmESQAgAAAACTCFIAAAAAYBJBCgAAAABMIkgBAAAAgEkEKQAAAAAwiSAFAAAAACYRpAAAAADAJIIUAAAAAJhEkAIAAAAAkwhSAAAAAGASQQoAAAAATCJIAQAAAIBJBCkAAAAAMIkgBQAAAAAmEaQAAAAAwCSCFAAAAACYRJACAAAAAJMIUgAAAABgEkEKAAAAAEwiSAEAAACASQQpAAAAADCJIAUAAAAAJhGkAAAAAMAkghQAAAAAmESQAgAAAACTCFIAAAAAYBJBCgAAAABMIkgBAAAAgEkEKQAAAAAwiSAFAAAAACYRpAAAAADAJIIUAAAAAJhEkAIAAAAAkwhSAAAAAGCSW4PU/Pnz1axZMwUHBys4OFhWq1WrVq1yHL906ZLi4uJUtWpVBQUFqW/fvjp9+rTTOY4fP64ePXooICBAYWFhGjt2rHJzc8v6UgAAAADcRNwapGrWrKmpU6cqOTlZu3fvVseOHdWrVy/t379fkjRq1CgtX75cy5Yt0+bNm3Xy5En16dPH8fm8vDz16NFDOTk5+vLLL7V48WItWrRIEyZMcNclAQAAALgJ+Liz8549ezptv/zyy5o/f7527NihmjVr6r333tOSJUvUsWNHSdLChQvVqFEj7dixQ23bttXatWt14MABrVu3TuHh4WrRooWmTJmicePGKSEhQX5+fu64LAAAAAA3OLcGqSvl5eVp2bJlunjxoqxWq5KTk2Wz2dS5c2dHm9tvv121a9fW9u3b1bZtW23fvl1NmzZVeHi4o03Xrl01bNgw7d+/Xy1btiy0r+zsbGVnZzu2MzIyJEk2m002m82levPbudq+JHgZXmXepyf0DXPcMTYBVzE+4akYm/BkjM+y5ep9dnuQ2rdvn6xWqy5duqSgoCB98sknio6OVkpKivz8/BQSEuLUPjw8XKmpqZKk1NRUpxCVfzz/WFESExM1adKkAvvXrl2rgIAAU/UnJSWZan89mqu5JGnlypVl1qcn9I3iKcuxCZjF+ISnYmzCkzE+y0ZWVpZL7dwepBo2bKiUlBSlp6fro48+UmxsrDZv3lyqfcbHx2v06NGO7YyMDNWqVUsxMTEKDg526Rw2m01JSUnq0qWLfH19S6tUJ4lbEyVJ8e3iy6Q/T+kb5rhjbAKuYnzCUzE24ckYn2Ur/2m1a3F7kPLz81P9+vUlSa1atdKuXbs0e/ZsPfLII8rJydH58+edZqVOnz6tiIgISVJERIS++uorp/Plr+qX36Yw/v7+8vf3L7Df19fX9OAszmeKy26xO/osa+7sG8VTlmMTMIvxCU/F2IQnY3yWDVfvscd9j5Tdbld2drZatWolX19frV+/3nHs0KFDOn78uKxWqyTJarVq3759SktLc7RJSkpScHCwoqOjy7x2AAAAADcHt85IxcfHq3v37qpdu7YuXLigJUuWaNOmTVqzZo0qV66sIUOGaPTo0QoNDVVwcLCefvppWa1WtW3bVpIUExOj6OhoDRgwQNOnT1dqaqpefPFFxcXFFTrjBAAAAAAlwa1BKi0tTQMHDtSpU6dUuXJlNWvWTGvWrFGXLl0kSTNnzpSXl5f69u2r7Oxsde3aVW+++abj897e3lqxYoWGDRsmq9WqwMBAxcbGavLkye66JAAAAAA3AbcGqffee++qxytUqKB58+Zp3rx5RbaJiopiJTkAAAAAZcrj3pECAAAAAE9HkAIAAAAAkwhSAAAAAGASQQoAAAAATHL7F/LCsyRsSvi/3zskFNkOAAAAuJkxIwUAAAAAJhGkAAAAAMAkghQAAAAAmESQAgAAAACTCFIAAAAAYBJBCgAAAABMIkgBAAAAgEkEKQAAAAAwiSAFAAAAACYRpAAAAADAJIIUAAAAAJhEkAIAAAAAkwhSAAAAAGASQQoAAAAATCJIAQAAAIBJBCkAAAAAMIkgBQAAAAAmEaQAAAAAwCSCFAAAAACYVCJB6vz58yVxGgAAAAAoF0wHqWnTpunDDz90bD/88MOqWrWqbrnlFn3zzTclWhwAAAAAeCLTQWrBggWqVauWJCkpKUlJSUlatWqVunfvrrFjx5Z4gQAAAADgaXzMfiA1NdURpFasWKGHH35YMTExqlOnjtq0aVPiBQIAAACApzE9I1WlShWdOHFCkrR69Wp17txZkmQYhvLy8kq2OgAAAADwQKZnpPr06aPHHntMDRo00JkzZ9S9e3dJ0p49e1S/fv0SLxAAAAAAPI3pIDVz5kzVqVNHJ06c0PTp0xUUFCRJOnXqlJ566qkSLxAAAAAAPI3pIOXr66tnn322wP5Ro0aVSEEAAAAA4OlcClKff/65yyd88MEHi10MAAAAAJQHLgWp3r17u3Qyi8XCghMAAAAAbnguBSm73V7adQAAAABAuWF6+fMrXbp0qaTqAAAAAIByw3SQysvL05QpU3TLLbcoKChIP/zwgyRp/Pjxeu+990q8QAAAAADwNKaD1Msvv6xFixZp+vTp8vPzc+xv0qSJ3n333RItDgAAAAA8kekg9f777+vtt99W//795e3t7djfvHlzfffddyVaHAAAAAB4ItNB6ueff1b9+vUL7Lfb7bLZbCVSFAAAAAB4MtNBKjo6Wv/9738L7P/oo4/UsmXLEikKAAAAADyZS8ufX2nChAmKjY3Vzz//LLvdro8//liHDh3S+++/rxUrVpRGjQAAAADgUUzPSPXq1UvLly/XunXrFBgYqAkTJujgwYNavny5unTpUho1AgAAAIBHKdb3SN17771KSkpSWlqasrKytHXrVsXExJg+T2Jiou68805VqlRJYWFh6t27tw4dOuTUpkOHDrJYLE4/f/3rX53aHD9+XD169FBAQIDCwsI0duxY5ebmFufSAAAAAOCaTD/al2/37t06ePCgpMvvTbVq1cr0OTZv3qy4uDjdeeedys3N1QsvvKCYmBgdOHBAgYGBjnZPPPGEJk+e7NgOCAhw/J6Xl6cePXooIiJCX375pU6dOqWBAwfK19dXr7zySnEvDwAAAACKZDpI/fTTT+rXr5+2bdumkJAQSdL58+d19913a+nSpapZs6bL51q9erXT9qJFixQWFqbk5GTdd999jv0BAQGKiIgo9Bxr167VgQMHtG7dOoWHh6tFixaaMmWKxo0bp4SEBKfvusqXnZ2t7Oxsx3ZGRoYkyWazubzyYH67slyp0MvwKvU+8/v4fT9l0TdKhjvGJuAqxic8FWMTnozxWbZcvc8WwzAMMyfu1q2bzp8/r8WLF6thw4aSpEOHDmnw4MEKDg4uEI7MOHz4sBo0aKB9+/apSZMmki4/2rd//34ZhqGIiAj17NlT48ePd8xKTZgwQZ9//rlSUlIc5zl69KhuvfVWff3114WuJJiQkKBJkyYV2L9kyRKn2S4AAAAAN5esrCw99thjSk9PV3BwcJHtTAepihUr6ssvvywQUJKTk3XvvfcqKyurWAXb7XY9+OCDOn/+vLZu3erY//bbbysqKkqRkZHau3evxo0bp7vuuksff/yxJGno0KE6duyY1qxZ4/hMVlaWAgMDtXLlSnXv3r1AX4XNSNWqVUu//vrrVW/WlWw2m5KSktSlSxf5+voW65rNStyaKEmKbxdf6n38vp+y6Bslwx1jE3AV4xOeirEJT8b4LFsZGRmqVq3aNYOU6Uf7atWqVeh0V15eniIjI82eziEuLk7ffvutU4iSLgelfE2bNlWNGjXUqVMnHTlyRPXq1StWX/7+/vL39y+w39fX1/TgLM5nistusTv6LO0+ft9PWfSNklWWYxMwi/EJT8XYhCdjfJYNV++x6VX7Xn31VT399NPavXu3Y9/u3bs1YsQIvfbaa2ZPJ0kaPny4VqxYoY0bN17zHas2bdpIuvwYoCRFRETo9OnTTm3yt4t6rwoAAAAArodLM1JVqlSRxWJxbF+8eFFt2rSRj8/lj+fm5srHx0ePP/64evfu7XLnhmHo6aef1ieffKJNmzapbt261/xM/rtQNWrUkCRZrVa9/PLLSktLU1hYmCQpKSlJwcHBio6OdrkWAAAAAHCVS0Fq1qxZpdJ5XFyclixZos8++0yVKlVSamqqJKly5cqqWLGijhw5oiVLluj+++9X1apVtXfvXo0aNUr33XefmjVrJkmKiYlRdHS0BgwYoOnTpys1NVUvvvii4uLiCn18DwAAAACul0tBKjY2tlQ6nz9/vqTLK/NdaeHChRo0aJD8/Py0bt06zZo1SxcvXlStWrXUt29fvfjii4623t7eWrFihYYNGyar1arAwEDFxsY6fe8UAAAAAJSkYn8hryRdunRJOTk5TvtcXfVOuvxo39XUqlVLmzdvvuZ5oqKitHLlSpf7BQAAAIDrYXqxiYsXL2r48OEKCwtTYGCgqlSp4vQDAAAAADc600Hqueee04YNGzR//nz5+/vr3Xff1aRJkxQZGan333+/NGoEAAAAAI9i+tG+5cuX6/3331eHDh00ePBg3Xvvvapfv76ioqL0wQcfqH///qVRJwAAAAB4DNMzUmfPntWtt94q6fL7UGfPnpUktWvXTlu2bCnZ6gAAAADAA5kOUrfeequOHj0qSbr99tv173//W9LlmaqQkJASLQ4AAAAAPJHpIDV48GB98803kqTnn39e8+bNU4UKFTRq1CiNHTu2xAsEAAAAAE9j+h2pUaNGOX7v3LmzvvvuOyUnJ6t+/fqOL8kFAAAAgBuZ6Rmp34uKilKfPn0UGhqqoUOHlkRNAAAAAODRrjtI5Ttz5ozee++9kjodAAAAAHgs04/24caTsCnB3SUAAAAA5UqJzUgBAAAAwM2CGSkUiZkqAAAAoHAuB6k+ffpc9fj58+evtxYAAAAAKBdcDlKVK1e+5vGBAwded0EAAAAA4OlcDlILFy4szToAAAAAoNxgsQkAAAAAMIkgBQAAAAAmEaQAAAAAwCSCFAAAAACY5FKQuuOOO3Tu3DlJ0uTJk5WVlVWqRQEAAACAJ3MpSB08eFAXL16UJE2aNEmZmZmlWhQ8V8KmBMcPAAAAcLNyafnzFi1aaPDgwWrXrp0Mw9Brr72moKCgQttOmDChRAsEAAAAAE/jUpBatGiRJk6cqBUrVshisWjVqlXy8Sn4UYvFQpACAAAAcMNzKUg1bNhQS5culSR5eXlp/fr1CgsLK9XCAAAAAMBTuRSkrmS320ujDgAAAAAoN0wHKUk6cuSIZs2apYMHD0qSoqOjNWLECNWrV69EiwMAAAAAT2T6e6TWrFmj6OhoffXVV2rWrJmaNWumnTt3qnHjxkpKSiqNGgEAAADAo5iekXr++ec1atQoTZ06tcD+cePGqUuXLiVWHAAAAAB4ItMzUgcPHtSQIUMK7H/88cd14MCBEikKAAAAADyZ6SBVvXp1paSkFNifkpLCSn4AAAAAbgqmH+174oknNHToUP3www+6++67JUnbtm3TtGnTNHr06BIvEAAAAAA8jekgNX78eFWqVEmvv/664uPjJUmRkZFKSEjQM888U+IFAgAAAICnMR2kLBaLRo0apVGjRunChQuSpEqVKpV4YQAAAADgqYr1PVL5CFAAAAAAbkamF5sAAAAAgJsdQQoAAAAATCJIAQAAAIBJpoKUzWZTp06d9P3335dWPQAAAADg8UwFKV9fX+3du7e0agEAAACAcsH0o31//vOf9d5775VGLQAAAABQLphe/jw3N1d///vftW7dOrVq1UqBgYFOx2fMmFFixQEAAACAJzIdpL799lvdcccdkqT//e9/TscsFkvJVAUAAAAAHsz0o30bN24s8mfDhg2mzpWYmKg777xTlSpVUlhYmHr37q1Dhw45tbl06ZLi4uJUtWpVBQUFqW/fvjp9+rRTm+PHj6tHjx4KCAhQWFiYxo4dq9zcXLOXBgAAAAAuKfby54cPH9aaNWv022+/SZIMwzB9js2bNysuLk47duxQUlKSbDabYmJidPHiRUebUaNGafny5Vq2bJk2b96skydPqk+fPo7jeXl56tGjh3JycvTll19q8eLFWrRokSZMmFDcSwMAAACAqzL9aN+ZM2f08MMPa+PGjbJYLPr+++916623asiQIapSpYpef/11l8+1evVqp+1FixYpLCxMycnJuu+++5Senq733ntPS5YsUceOHSVJCxcuVKNGjbRjxw61bdtWa9eu1YEDB7Ru3TqFh4erRYsWmjJlisaNG6eEhAT5+fmZvUQAAAAAuCrTQWrUqFHy9fXV8ePH1ahRI8f+Rx55RKNHjzYVpH4vPT1dkhQaGipJSk5Ols1mU+fOnR1tbr/9dtWuXVvbt29X27ZttX37djVt2lTh4eGONl27dtWwYcO0f/9+tWzZskA/2dnZys7OdmxnZGRIuvw9WTabzaVa89u52r4keBlepdJn/nnNKstrh+vcMTYBVzE+4akYm/BkjM+y5ep9Nh2k1q5dqzVr1qhmzZpO+xs0aKBjx46ZPZ2D3W7XyJEjdc8996hJkyaSpNTUVPn5+SkkJMSpbXh4uFJTUx1trgxR+cfzjxUmMTFRkyZNKrB/7dq1CggIMFV3UlKSqfbXo7maS5JWrlxZKuc1q6TrQMkqy7EJmMX4hKdibMKTMT7LRlZWlkvtTAepixcvFho2zp49K39/f7Onc4iLi9O3336rrVu3FvscroqPj9fo0aMd2xkZGapVq5ZiYmIUHBzs0jlsNpuSkpLUpUsX+fr6llapThK3JkqS4tvFl8p5zSrpOlAy3DE2AVcxPuGpGJvwZIzPspX/tNq1mA5S9957r95//31NmTJF0uUlz+12u6ZPn64//OEPZk8nSRo+fLhWrFihLVu2OM10RUREKCcnR+fPn3ealTp9+rQiIiIcbb766iun8+Wv6pff5vf8/f0LDX2+vr6mB2dxPlNcdovd0WdpnNcs/ovs2cpybAJmMT7hqRib8GSMz7Lh6j02/XLM9OnT9fbbb6t79+7KycnRc889pyZNmmjLli2aNm2aqXMZhqHhw4frk08+0YYNG1S3bl2n461atZKvr6/Wr1/v2Hfo0CEdP35cVqtVkmS1WrVv3z6lpaU52iQlJSk4OFjR0dFmLw8AAAAArsn0jFSTJk30v//9T2+88YYqVaqkzMxM9enTR3FxcapRo4apc8XFxWnJkiX67LPPVKlSJcc7TZUrV1bFihVVuXJlDRkyRKNHj1ZoaKiCg4P19NNPy2q1qm3btpKkmJgYRUdHa8CAAZo+fbpSU1P14osvKi4u7roeNQQAAACAopgOUtLloPO3v/3tujufP3++JKlDhw5O+xcuXKhBgwZJkmbOnCkvLy/17dtX2dnZ6tq1q958801HW29vb61YsULDhg2T1WpVYGCgYmNjNXny5OuuDwAAAAAKU6wgde7cOb333ns6ePCgJCk6OlqDBw92LFvuKle+xLdChQqaN2+e5s2bV2SbqKgoVpADAAAAUGZMvyO1ZcsW1alTR3PmzNG5c+d07tw5zZkzR3Xr1tWWLVtKo0YAAAAA8CimZ6Ti4uL0yCOPaP78+fL29pYk5eXl6amnnlJcXJz27dtX4kUCAAAAgCcxPSN1+PBhjRkzxhGipMvvKY0ePVqHDx8u0eIAAAAAwBOZDlJ33HGH492oKx08eFDNmzcvkaIAAAAAwJO59Gjf3r17Hb8/88wzGjFihA4fPuxYgnzHjh2aN2+epk6dWjpVAgAAAIAHcSlItWjRQhaLxWmVveeee65Au8cee0yPPPJIyVUHAAAAAB7IpSB19OjR0q4DAAAAAMoNl4JUVFRUadcBAAAAAOVGsb6Q9+TJk9q6davS0tJkt9udjj3zzDMlUhgAAAAAeCrTQWrRokV68skn5efnp6pVq8pisTiOWSwWghQAAACAG57pIDV+/HhNmDBB8fHx8vIyvXo6AAAAAJR7ppNQVlaWHn30UUIUAAAAgJuW6TQ0ZMgQLVu2rDRqAQAAAIBywfSjfYmJiXrggQe0evVqNW3aVL6+vk7HZ8yYUWLFAQAAAIAnKlaQWrNmjRo2bChJBRabAAAAAIAbnekg9frrr+vvf/+7Bg0aVArlAAAAAIDnM/2OlL+/v+65557SqAUAAAAAygXTQWrEiBGaO3duadQCAAAAAOWC6Uf7vvrqK23YsEErVqxQ48aNCyw28fHHH5dYcQAAAADgiUwHqZCQEPXp06c0agEAAACAcsF0kFq4cGFp1AEAAAAA5Ybpd6QAAAAA4GZnekaqbt26V/2+qB9++OG6CgIAAAAAT2c6SI0cOdJp22azac+ePVq9erXGjh1bUnUBAAAAgMcyHaRGjBhR6P558+Zp9+7d110QAAAAAHi6EntHqnv37vrPf/5TUqcDAAAAAI9VYkHqo48+UmhoaEmdDgAAAAA8lulH+1q2bOm02IRhGEpNTdUvv/yiN998s0SLAwAAAABPZDpI9e7d22nby8tL1atXV4cOHXT77beXVF0AAAAA4LFMB6mJEyeWRh0AAAAAUG7whbwAAAAAYJLLM1JeXl5X/SJeSbJYLMrNzb3uogAAAADAk7kcpD755JMij23fvl1z5syR3W4vkaIAAAAAwJO5HKR69epVYN+hQ4f0/PPPa/ny5erfv78mT55cosUBAAAAgCcq1jtSJ0+e1BNPPKGmTZsqNzdXKSkpWrx4saKiokq6PgAAAADwOKaCVHp6usaNG6f69etr//79Wr9+vZYvX64mTZqUVn0AAAAA4HFcfrRv+vTpmjZtmiIiIvSvf/2r0Ef9AAAAAOBm4HKQev7551WxYkXVr19fixcv1uLFiwtt9/HHH5dYcQAAAADgiVwOUgMHDrzm8ucAAAAAcDNwOUgtWrSoFMsAAAAAgPKjWKv2AQAAAMDNjCAFAAAAACYRpAAAAADAJLcGqS1btqhnz56KjIyUxWLRp59+6nR80KBBslgsTj/dunVzanP27Fn1799fwcHBCgkJ0ZAhQ5SZmVmGVwEAAADgZuPWIHXx4kU1b95c8+bNK7JNt27ddOrUKcfPv/71L6fj/fv31/79+5WUlKQVK1Zoy5YtGjp0aGmXDgAAAOAm5vKqfaWhe/fu6t69+1Xb+Pv7KyIiotBjBw8e1OrVq7Vr1y61bt1akjR37lzdf//9eu211xQZGVniNQMAAACAW4OUKzZt2qSwsDBVqVJFHTt21EsvvaSqVatKkrZv366QkBBHiJKkzp07y8vLSzt37tQf//jHQs+ZnZ2t7Oxsx3ZGRoYkyWazyWazuVRXfjtX25cEL8OrVPrMP69ZZXntcJ07xibgKsYnPBVjE56M8Vm2XL3PHh2kunXrpj59+qhu3bo6cuSIXnjhBXXv3l3bt2+Xt7e3UlNTFRYW5vQZHx8fhYaGKjU1tcjzJiYmatKkSQX2r127VgEBAaZqTEpKMtX+ejRXc0nSypUrS+W8ZpV0HShZZTk2AbMYn/BUjE14MsZn2cjKynKpnUcHqUcffdTxe9OmTdWsWTPVq1dPmzZtUqdOnYp93vj4eI0ePdqxnZGRoVq1aikmJkbBwcEuncNmsykpKUldunSRr69vsWsxI3FroiQpvl18qZzXrJKuAyXDHWMTcBXjE56KsQlPxvgsW/lPq12LRwep37v11ltVrVo1HT58WJ06dVJERITS0tKc2uTm5urs2bNFvlclXX7vyt/fv8B+X19f04OzOJ8pLrvF7uizNM5rFv9F9mxlOTYBsxif8FSMTXgyxmfZcPUel6vvkfrpp5905swZ1ahRQ5JktVp1/vx5JScnO9ps2LBBdrtdbdq0cVeZAAAAAG5wbp2RyszM1OHDhx3bR48eVUpKikJDQxUaGqpJkyapb9++ioiI0JEjR/Tcc8+pfv366tq1qySpUaNG6tatm5544gktWLBANptNw4cP16OPPsqKfQAAAABKjVtnpHbv3q2WLVuqZcuWkqTRo0erZcuWmjBhgry9vbV37149+OCDuu222zRkyBC1atVK//3vf50ey/vggw90++23q1OnTrr//vvVrl07vf322+66JAAAAAA3AbfOSHXo0EGGYRR5fM2aNdc8R2hoqJYsWVKSZQEAAADAVZWrd6QAAAAAwBMQpAAAAADAJIIUAAAAAJhEkAIAAAAAkwhSAAAAAGASQQoAAAAATCJIAQAAAIBJBCkAAAAAMIkgBQAAAAAmEaQAAAAAwCSCFAAAAACYRJACAAAAAJMIUgAAAABgEkEKAAAAAEwiSAEAAACASQQpAAAAADCJIAUAAAAAJhGkAAAAAMAkghQAAAAAmESQAgAAAACTCFIAAAAAYBJBCgAAAABMIkgBAAAAgEkEKQAAAAAwiSAFAAAAACYRpAAAAADAJIIUAAAAAJhEkAIAAAAAkwhSAAAAAGASQQoAAAAATCJIAQAAAIBJBCkAAAAAMIkgBQAAAAAmEaQAAAAAwCSCFAAAAACYRJACAAAAAJMIUgAAAABgEkEKAAAAAEwiSAEAAACASQQpAAAAADCJIAUAAAAAJhGkAAAAAMAkghQAAAAAmOTWILVlyxb17NlTkZGRslgs+vTTT52OG4ahCRMmqEaNGqpYsaI6d+6s77//3qnN2bNn1b9/fwUHByskJERDhgxRZmZmGV4FAAAAgJuNW4PUxYsX1bx5c82bN6/Q49OnT9ecOXO0YMEC7dy5U4GBgeratasuXbrkaNO/f3/t379fSUlJWrFihbZs2aKhQ4eW1SUAAAAAuAn5uLPz7t27q3v37oUeMwxDs2bN0osvvqhevXpJkt5//32Fh4fr008/1aOPPqqDBw9q9erV2rVrl1q3bi1Jmjt3ru6//3699tprioyMLPTc2dnZys7OdmxnZGRIkmw2m2w2m0u157dztX1J8DK8SqXP/POaVZbXDte5Y2wCrmJ8wlMxNuHJGJ9ly9X7bDEMwyjlWlxisVj0ySefqHfv3pKkH374QfXq1dOePXvUokULR7v27durRYsWmj17tv7+979rzJgxOnfunON4bm6uKlSooGXLlumPf/xjoX0lJCRo0qRJBfYvWbJEAQEBJXpdAAAAAMqPrKwsPfbYY0pPT1dwcHCR7dw6I3U1qampkqTw8HCn/eHh4Y5jqampCgsLczru4+Oj0NBQR5vCxMfHa/To0Y7tjIwM1apVSzExMVe9WVey2WxKSkpSly5d5Ovr69Jnrlfi1kRJUny7+FI5r1klXQdKhjvGJuAqxic8FWMTnozxWbbyn1a7Fo8NUqXJ399f/v7+Bfb7+vqaHpzF+Uxx2S12R5+lcV6z+C+yZyvLsQmYxfiEp2JswpMxPsuGq/fYY5c/j4iIkCSdPn3aaf/p06cdxyIiIpSWluZ0PDc3V2fPnnW0AQAAAICS5rFBqm7duoqIiND69esd+zIyMrRz505ZrVZJktVq1fnz55WcnOxos2HDBtntdrVp06bMawYAAABwc3Dro32ZmZk6fPiwY/vo0aNKSUlRaGioateurZEjR+qll15SgwYNVLduXY0fP16RkZGOBSkaNWqkbt266YknntCCBQtks9k0fPhwPfroo0Wu2AcAAAAA18utQWr37t36wx/+4NjOXwAiNjZWixYt0nPPPaeLFy9q6NChOn/+vNq1a6fVq1erQoUKjs988MEHGj58uDp16iQvLy/17dtXc+bMKfNrAQAAAHDzcGuQ6tChg662+rrFYtHkyZM1efLkItuEhoZqyZIlpVEeAAAAABTKY9+RAgAAAABPRZACAAAAAJMIUgAAAABgEkEKAAAAAExy62ITuH4JmxL+7/cOCUW2AwAAAFBymJECAAAAAJMIUgAAAABgEkEKAAAAAEwiSAEAAACASQQpAAAAADCJIAUAAAAAJhGkAAAAAMAkvkcKHonvxwIAAIAnY0YKAAAAAEwiSAEAAACASQQpAAAAADCJIAUAAAAAJhGkAAAAAMAkghQAAAAAmESQAgAAAACTCFIAAAAAYBJBCgAAAABMIkgBAAAAgEkEKQAAAAAwiSAFAAAAACYRpAAAAADAJIIUAAAAAJhEkAIAAAAAk3zcXQDMS9iU4O4SAAAAgJsaM1IAAAAAYBJBCgAAAABMIkgBAAAAgEkEKQAAAAAwiSAFAAAAACYRpAAAAADAJIIUAAAAAJhEkAIAAAAAkwhSAAAAAGASQQoAAAAATCJIAQAAAIBJBCkAAAAAMIkgBQAAAAAmeXSQSkhIkMVicfq5/fbbHccvXbqkuLg4Va1aVUFBQerbt69Onz7txooBAAAA3Aw8OkhJUuPGjXXq1CnHz9atWx3HRo0apeXLl2vZsmXavHmzTp48qT59+rixWgAAAAA3Ax93F3AtPj4+ioiIKLA/PT1d7733npYsWaKOHTtKkhYuXKhGjRppx44datu2bVmXCgAAAOAm4fFB6vvvv1dkZKQqVKggq9WqxMRE1a5dW8nJybLZbOrcubOj7e23367atWtr+/btVw1S2dnZys7OdmxnZGRIkmw2m2w2m0t15bdztX1J8DKuPoFY3Fqudd6S7s8VV9ZUlvf4RuCOsQm4ivEJT8XYhCdjfJYtV++zxTAMo5RrKbZVq1YpMzNTDRs21KlTpzRp0iT9/PPP+vbbb7V8+XINHjzYKRBJ0l133aU//OEPmjZtWpHnTUhI0KRJkwrsX7JkiQICAkr8OgAAAACUD1lZWXrssceUnp6u4ODgItt5dJD6vfPnzysqKkozZsxQxYoVix2kCpuRqlWrln799der3qwr2Ww2JSUlqUuXLvL19S3eBZmUuDXxqsfj28WXynlLuj9XXFlTafbjrv5KkzvGJuAqxic8FWMTnozxWbYyMjJUrVq1awYpj3+070ohISG67bbbdPjwYXXp0kU5OTk6f/68QkJCHG1Onz5d6DtVV/L395e/v3+B/b6+vqYHZ3E+U1x2i/2atZTGeUu6P1dcWVNZ3N+y7q8slOXYBMxifMJTMTbhyRifZcPVe1yuglRmZqaOHDmiAQMGqFWrVvL19dX69evVt29fSdKhQ4d0/PhxWa1WN1fq+RI2Jbi7BAAAAKDc8ugg9eyzz6pnz56KiorSyZMnNXHiRHl7e6tfv36qXLmyhgwZotGjRys0NFTBwcF6+umnZbVaWbEPLiFMAgAAoLg8Okj99NNP6tevn86cOaPq1aurXbt22rFjh6pXry5Jmjlzpry8vNS3b19lZ2era9euevPNN91cNQAAAIAbnUcHqaVLl171eIUKFTRv3jzNmzevjCoCAAAAAKl4XyAElKGETQk8hgcAAACPQpACAAAAAJMIUgAAAABgEkEKAAAAAEwiSAEAAACASQQpAAAAADCJIAVcBSsGAgAAoDAEKQAAAAAwyaO/kBee7cqZmoQOCUW2AwAAAG40zEgBAAAAgEkEKQAAAAAwiSAFAAAAACYRpAAAAADAJIIUAAAAAJhEkAIAAAAAk1j+/CZys36xLMu0AwAAoKQRpG4g7gwMRYU0ggsAAABuRDzaBwAAAAAmMSPl4W7Wx/FKAvcOAAAApYUZKQAAAAAwiRkpeAxmkAAAAFBeEKQAN2AlQQAAgPKNR/sAAAAAwCRmpFDmmI0BAABAeUeQQrnhzu+qIvwBAADgSgQplInytJBEeaoVAAAA7sE7UgAAAABgEkEKAAAAAEzi0T64FY/RAQAAoDxiRgoAAAAATGJGCuUeK+oVH/cOAACgeJiRAgAAAACTmJHCDcWT37ny5NoAAABgDkEKNxXCjGvy7xOP+wEAABSOR/sAAAAAwCRmpIAbVOLWRNktdknMLAEAAJQ0ZqQAAAAAwCRmpG4CvBdUssr7kuGMBwAAgOtHkAI8SGmFtLIKTyxSAQAAbhYEKQ/EjEH5VNwQVNJ/78StiWqu5qY/VxbjrrzP5gEAAOQjSKFU3eihsDSvj9kdc8zcLwIdAAC4XgSpG9SNHmBuVkX9XUsrDJTELNuNGlRuhmsEAABFI0gBHs5TQnF5DA6u3LvC2pSX6wMAAO5zwyx/Pm/ePNWpU0cVKlRQmzZt9NVXX7m7JAAAAAA3qBtiRurDDz/U6NGjtWDBArVp00azZs1S165ddejQIYWFhbm7PKDUXTmr4lUG//9ISc+SleRslztm8MrL+2zXejS0PM46uuJGvS4AgHvdEEFqxowZeuKJJzR48GBJ0oIFC/TFF1/o73//u55//nk3V4ebmac8ludOZu/Btdpf+S/CpXV/S+JfvEvzHIXtd0dYKC8B0oyyuo9lce/KekwQWAHcbMp9kMrJyVFycrLi4+Md+7y8vNS5c2dt37690M9kZ2crOzvbsZ2eni5JOnv2rGw2m0v92mw2ZWVl6cyZM/L19b2OKygoJzOnRM+HsvfCihfc1reX4aWsrCzleOXIbrG7rY5rKe49Kut7e+bMGcfvr29//apti6rNTM1jrGMcv1/5z4Ir67hyf2HnvnJfUee7Uv65izrvleco7B4UdY8K+5yX4aXGWY01afUk2S12pzZmXOtvUdR1F3a/XLnnhfVd3Nqv7KeoPq6lqPtcWB+/7+da9Zu5t670V5KKqq2oMXqtv9GVbZ9p/Uyp/e/6zc7M36Sk+zTbX2FjrKRrLs79KI1/73TH3+Vqdbizht+7cOGCJMkwjKu2sxjXauHhTp48qVtuuUVffvmlrFarY/9zzz2nzZs3a+fOnQU+k5CQoEmTJpVlmQAAAADKkRMnTqhmzZpFHi/3M1LFER8fr9GjRzu27Xa7zp49q6pVq8pisbh0joyMDNWqVUsnTpxQcHBwaZUKmMbYhCdjfMJTMTbhyRifZcswDF24cEGRkZFXbVfug1S1atXk7e2t06dPO+0/ffq0IiIiCv2Mv7+//P39nfaFhIQUq//g4GAGNDwSYxOejPEJT8XYhCdjfJadypUrX7NNuV/+3M/PT61atdL69esd++x2u9avX+/0qB8AAAAAlJRyPyMlSaNHj1ZsbKxat26tu+66S7NmzdLFixcdq/gBAAAAQEm6IYLUI488ol9++UUTJkxQamqqWrRoodWrVys8PLzU+vT399fEiRMLPCIIuBtjE56M8QlPxdiEJ2N8eqZyv2ofAAAAAJS1cv+OFAAAAACUNYIUAAAAAJhEkAIAAAAAkwhSAAAAAGASQaqY5s2bpzp16qhChQpq06aNvvrqK3eXhBvcli1b1LNnT0VGRspisejTTz91Om4YhiZMmKAaNWqoYsWK6ty5s77//nunNmfPnlX//v0VHByskJAQDRkyRJmZmWV4FbgRJSYm6s4771SlSpUUFham3r1769ChQ05tLl26pLi4OFWtWlVBQUHq27dvgS9SP378uHr06KGAgACFhYVp7Nixys3NLctLwQ1m/vz5atasmeNLTK1Wq1atWuU4zriEp5g6daosFotGjhzp2Mf49HwEqWL48MMPNXr0aE2cOFFff/21mjdvrq5duyotLc3dpeEGdvHiRTVv3lzz5s0r9Pj06dM1Z84cLViwQDt37lRgYKC6du2qS5cuOdr0799f+/fvV1JSklasWKEtW7Zo6NChZXUJuEFt3rxZcXFx2rFjh5KSkmSz2RQTE6OLFy862owaNUrLly/XsmXLtHnzZp08eVJ9+vRxHM/Ly1OPHj2Uk5OjL7/8UosXL9aiRYs0YcIEd1wSbhA1a9bU1KlTlZycrN27d6tjx47q1auX9u/fL4lxCc+wa9cuvfXWW2rWrJnTfsZnOWDAtLvuusuIi4tzbOfl5RmRkZFGYmKiG6vCzUSS8cknnzi27Xa7ERERYbz66quOfefPnzf8/f2Nf/3rX4ZhGMaBAwcMScauXbscbVatWmVYLBbj559/LrPaceNLS0szJBmbN282DOPyWPT19TWWLVvmaHPw4EFDkrF9+3bDMAxj5cqVhpeXl5GamupoM3/+fCM4ONjIzs4u2wvADa1KlSrGu+++y7iER7hw4YLRoEEDIykpyWjfvr0xYsQIwzD452Z5wYyUSTk5OUpOTlbnzp0d+7y8vNS5c2dt377djZXhZnb06FGlpqY6jcvKlSurTZs2jnG5fft2hYSEqHXr1o42nTt3lpeXl3bu3FnmNePGlZ6eLkkKDQ2VJCUnJ8tmszmNz9tvv121a9d2Gp9NmzZ1+iL1rl27KiMjwzF7AFyPvLw8LV26VBcvXpTVamVcwiPExcWpR48eTuNQ4p+b5YWPuwsob3799Vfl5eU5DVpJCg8P13fffeemqnCzS01NlaRCx2X+sdTUVIWFhTkd9/HxUWhoqKMNcL3sdrtGjhype+65R02aNJF0eez5+fkpJCTEqe3vx2dh4zf/GFBc+/btk9Vq1aVLlxQUFKRPPvlE0dHRSklJYVzCrZYuXaqvv/5au3btKnCMf26WDwQpAECJiYuL07fffqutW7e6uxRAktSwYUOlpKQoPT1dH330kWJjY7V582Z3l4Wb3IkTJzRixAglJSWpQoUK7i4HxcSjfSZVq1ZN3t7eBVZNOX36tCIiItxUFW52+WPvauMyIiKiwIIoubm5Onv2LGMXJWL48OFasWKFNm7cqJo1azr2R0REKCcnR+fPn3dq//vxWdj4zT8GFJefn5/q16+vVq1aKTExUc2bN9fs2bMZl3Cr5ORkpaWl6Y477pCPj498fHy0efNmzZkzRz4+PgoPD2d8lgMEKZP8/PzUqlUrrV+/3rHPbrdr/fr1slqtbqwMN7O6desqIiLCaVxmZGRo586djnFptVp1/vx5JScnO9ps2LBBdrtdbdq0KfOaceMwDEPDhw/XJ598og0bNqhu3bpOx1u1aiVfX1+n8Xno0CEdP37caXzu27fPKewnJSUpODhY0dHRZXMhuCnY7XZlZ2czLuFWnTp10r59+5SSkuL4ad26tfr37+/4nfFZDrh7tYvyaOnSpYa/v7+xaNEi48CBA8bQoUONkJAQp1VTgJJ24cIFY8+ePcaePXsMScaMGTOMPXv2GMeOHTMMwzCmTp1qhISEGJ999pmxd+9eo1evXkbdunWN3377zXGObt26GS1btjR27txpbN261WjQoIHRr18/d10SbhDDhg0zKleubGzatMk4deqU4ycrK8vR5q9//atRu3ZtY8OGDcbu3bsNq9VqWK1Wx/Hc3FyjSZMmRkxMjJGSkmKsXr3aqF69uhEfH++OS8IN4vnnnzc2b95sHD161Ni7d6/x/PPPGxaLxVi7dq1hGIxLeJYrV+0zDMZneUCQKqa5c+catWvXNvz8/Iy77rrL2LFjh7tLwg1u48aNhqQCP7GxsYZhXF4Cffz48UZ4eLjh7+9vdOrUyTh06JDTOc6cOWP069fPCAoKMoKDg43BgwcbFy5ccMPV4EZS2LiUZCxcuNDR5rfffjOeeuopo0qVKkZAQIDxxz/+0Th16pTTeX788Ueje/fuRsWKFY1q1aoZY8aMMWw2WxlfDW4kjz/+uBEVFWX4+fkZ1atXNzp16uQIUYbBuIRn+X2QYnx6PothGIZ75sIAAAAAoHziHSkAAAAAMIkgBQAAAAAmEaQAAAAAwCSCFAAAAACYRJACAAAAAJMIUgAAAABgEkEKAAAAAEwiSAEAAACASQQpAIB+/PFHWSwWpaSkuLsUh++++05t27ZVhQoV1KJFC3eXg2uoU6eOZs2adV3nSEhI4G8NoNwgSAGABxg0aJAsFoumTp3qtP/TTz+VxWJxU1XuNXHiRAUGBurQoUNav359oW0GDRqk3r17l21hNyBPDNIA4OkIUgDgISpUqKBp06bp3Llz7i6lxOTk5BT7s0eOHFG7du0UFRWlqlWrlmBVN6+8vDzZ7XZ3lwEANwSCFAB4iM6dOysiIkKJiYlFtins0adZs2apTp06ju38WZpXXnlF4eHhCgkJ0eTJk5Wbm6uxY8cqNDRUNWvW1MKFCwuc/7vvvtPdd9+tChUqqEmTJtq8ebPT8W+//Vbdu3dXUFCQwsPDNWDAAP3666+O4x06dNDw4cM1cuRIVatWTV27di30Oux2uyZPnqyaNWvK399fLVq00OrVqx3HLRaLkpOTNXnyZFksFiUkJFzlzv2fDh066Omnn9bIkSNVpUoVhYeH65133tHFixc1ePBgVapUSfXr19eqVascn8nLy9OQIUNUt25dVaxYUQ0bNtTs2bOdzpubm6tnnnlGISEhqlq1qsaNG6fY2Fin2TC73a7ExETHeZo3b66PPvrIcfzcuXPq37+/qlevrooVK6pBgwaF/g1+fy+HDx+uypUrq1q1aho/frwMw3C0yc7O1rPPPqtbbrlFgYGBatOmjTZt2uQ4vmjRIoWEhOjzzz9XdHS0/P39dfz4cZfu5ZWOHDmiXr16KTw8XEFBQbrzzju1bt26Au0uXLigfv36KTAwULfccovmzZvndPz8+fP6y1/+ourVqys4OFgdO3bUN998Y7oeAPAEBCkA8BDe3t565ZVXNHfuXP3000/Xda4NGzbo5MmT2rJli2bMmKGJEyfqgQceUJUqVbRz50799a9/1ZNPPlmgn7Fjx2rMmDHas2ePrFarevbsqTNnzki6/C/BHTt2VMuWLbV7926tXr1ap0+f1sMPP+x0jsWLF8vPz0/btm3TggULCq1v9uzZev311/Xaa69p79696tq1qx588EF9//33kqRTp06pcePGGjNmjE6dOqVnn33W5WtfvHixqlWrpq+++kpPP/20hg0bpj/96U+6++679fXXXysmJkYDBgxQVlaWpMsBqGbNmlq2bJkOHDigCRMm6IUXXtC///1vxzmnTZumDz74QAsXLtS2bduUkZGhTz/91KnfxMREvf/++1qwYIH279+vUaNG6c9//rMjjI4fP14HDhzQqlWrdPDgQc2fP1/VqlW75rX4+Pjoq6++0uzZszVjxgy9++67juPDhw/X9u3btXTpUu3du1d/+tOf1K1bN8d9lKSsrCxNmzZN7777rvbv36+wsDCX72W+zMxM3X///Vq/fr327Nmjbt26qWfPngVC2auvvqrmzZtrz549ev755zVixAglJSU5jv/pT39SWlqaVq1apeTkZN1xxx3q1KmTzp49a7omAHA7AwDgdrGxsUavXr0MwzCMtm3bGo8//rhhGIbxySefGFf+o3rixIlG8+bNnT47c+ZMIyoqyulcUVFRRl5enmNfw4YNjXvvvdexnZubawQGBhr/+te/DMMwjKNHjxqSjKlTpzra2Gw2o2bNmsa0adMMwzCMKVOmGDExMU59nzhxwpBkHDp0yDAMw2jfvr3RsmXLa15vZGSk8fLLLzvtu/POO42nnnrKsd28eXNj4sSJVz3Plfctv/927doVuM4BAwY49p06dcqQZGzfvr3I88bFxRl9+/Z1bIeHhxuvvvqq03lr167t6PvSpUtGQECA8eWXXzqdZ8iQIUa/fv0MwzCMnj17GoMHD77q9Vypffv2RqNGjQy73e7YN27cOKNRo0aGYRjGsWPHDG9vb+Pnn392+lynTp2M+Ph4wzAMY+HChYYkIyUl5ap95f/99+zZ43J9jRs3NubOnevYjoqKMrp16+bU5pFHHjG6d+9uGIZh/Pe//zWCg4ONS5cuObWpV6+e8dZbbxmGUfj4BgBP5ePOEAcAKGjatGnq2LGjqVmY32vcuLG8vP7voYPw8HA1adLEse3t7a2qVasqLS3N6XNWq9Xxu4+Pj1q3bq2DBw9Kkr755htt3LhRQUFBBfo7cuSIbrvtNklSq1atrlpbRkaGTp48qXvuucdp/z333FMij3k1a9bM8Xv+dTZt2tSxLzw8XJKcrn3evHn6+9//ruPHj+u3335TTk6O4xHK9PR0nT59WnfddZfTeVu1auV43+jw4cPKyspSly5dnGrJyclRy5YtJUnDhg1T3759HbNivXv31t13333Va2nbtq3TYiNWq1Wvv/668vLytG/fPuXl5Tnue77s7Gynd8r8/Pyc7klxZGZmKiEhQV988YVOnTql3Nxc/fbbbwVmpK4cP/nb+Sv5ffPNN8rMzCzwvttvv/2mI0eOXFd9AOAOBCkA8DD33Xefunbtqvj4eA0aNMjpmJeXl9M7MpJks9kKnMPX19dp22KxFLrPzMIDmZmZ6tmzp6ZNm1bgWI0aNRy/BwYGunzO0nCta88PJvnXvnTpUj377LN6/fXXZbVaValSJb366qvauXOny31mZmZKkr744gvdcsstTsf8/f0lSd27d9exY8e0cuVKJSUlqVOnToqLi9Nrr71m/iL/f5/e3t5KTk6Wt7e307Erw27FihWve+XHZ599VklJSXrttddUv359VaxYUQ899JCpxUQyMzNVo0YNp3e48oWEhFxXfQDgDgQpAPBAU6dOVYsWLdSwYUOn/dWrV1dqaqoMw3D8y3FJLlm9Y8cO3XfffZIuL7CQnJys4cOHS5LuuOMO/ec//1GdOnXk41P8//kIDg5WZGSktm3bpvbt2zv2b9u2zWnWp6xs27ZNd999t5566inHvitnSCpXrqzw8HDt2rXLcW/y8vL09ddfO2atrlzI4cpr+r3q1asrNjZWsbGxuvfeezV27NirBqnfh7kdO3aoQYMG8vb2VsuWLZWXl6e0tDTde++9xbl0l23btk2DBg3SH//4R0mXQ9GPP/5YoN2OHTsKbDdq1EjS5fGTmpoqHx8fp8VRAKC8IkgBgAdq2rSp+vfvrzlz5jjt79Chg3755RdNnz5dDz30kFavXq1Vq1YpODi4RPqdN2+eGjRooEaNGmnmzJk6d+6cHn/8cUlSXFyc3nnnHfXr10/PPfecQkNDdfjwYS1dulTvvvtugVmRqxk7dqwmTpyoevXqqUWLFlq4cKFSUlL0wQcflMh1mNGgQQO9//77WrNmjerWrat//OMf2rVrl+rWreto8/TTTysxMVH169fX7bffrrlz5+rcuXOOMFupUiU9++yzGjVqlOx2u9q1a6f09HRt27ZNwcHBio2N1YQJE9SqVSs1btxY2dnZWrFihSNkFOX48eMaPXq0nnzySX399deaO3euXn/9dUnSbbfdpv79+2vgwIF6/fXX1bJlS/3yyy9av369mjVrph49epi+F4cOHSqwr3HjxmrQoIE+/vhj9ezZUxaLRePHjy90NnPbtm2aPn26evfuraSkJC1btkxffPGFpMurUlqtVvXu3VvTp0/XbbfdppMnT+qLL77QH//4R7Vu3dp0vQDgTgQpAPBQkydP1ocffui0r1GjRnrzzTf1yiuvaMqUKerbt6+effZZvf322yXS59SpUzV16lSlpKSofv36+vzzzx0ry+XPIo0bN04xMTHKzs5WVFSUunXr5vQ+liueeeYZpaena8yYMUpLS1N0dLQ+//xzNWjQoESuw4wnn3xSe/bs0SOPPCKLxaJ+/frpqaeecloifdy4cUpNTdXAgQPl7e2toUOHqmvXrk7hccqUKapevboSExP1ww8/KCQkRHfccYdeeOEFSZffVYqPj9ePP/6oihUr6t5779XSpUuvWtvAgQP122+/6a677pK3t7dGjBihoUOHOo4vXLhQL730ksaMGaOff/5Z1apVU9u2bfXAAw8U6148+uijBfadOHFCM2bM0OOPP667775b1apV07hx45SRkVGg7ZgxY7R7925NmjRJwcHBmjFjhmMJfIvFopUrV+pvf/ubBg8erF9++UURERG67777HO+tAUB5YjF+/7A9AAC4KrvdrkaNGunhhx/WlClTSqWPDh06qEWLFo7FGgAAnoUZKQAAruHYsWNau3at2rdvr+zsbL3xxhs6evSoHnvsMXeXBgBwE76QFwCAa/Dy8tKiRYt055136p577tG+ffu0bt26a77jBAC4cfFoHwAAAACYxIwUAAAAAJhEkAIAAAAAkwhSAAAAAGASQQoAAAAATCJIAQAAAIBJBCkAAAAAMIkgBQAAAAAmEaQAAAAAwKT/B6TR4F41RDtXAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "excel_file = \"directory_consumer_grade_images.xlsx\"\n",
    "df_xls = pd.read_excel(excel_file)\n",
    "\n",
    "# encode the labels\n",
    "df_xls[\"encoded_label\"] = label_encoder.fit_transform(df_xls[\"Name\"])\n",
    "\n",
    "# Check for missing labels\n",
    "missing_labels = df_xls['encoded_label'].isnull().sum()\n",
    "print(\"Number of missing labels:\", missing_labels)\n",
    "\n",
    "# Remove data points without a label\n",
    "df_xls = df_xls.dropna(subset=['encoded_label'])\n",
    "\n",
    "# Check the number of labels again\n",
    "print(\"Total number of labels after removing missing labels: \", len(df_xls[\"encoded_label\"]))\n",
    "\n",
    "# Combine old and new df\n",
    "df_combined = pd.concat([df, df_xls])\n",
    "\n",
    "# Check if the data is imbalanced\n",
    "label_counts = df_combined['encoded_label'].value_counts()\n",
    "print(label_counts)\n",
    "\n",
    "# Check if the data is imbalanced\n",
    "label_counts = df_combined['encoded_label'].value_counts()\n",
    "\n",
    "# Plot the label counts\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.hist(label_counts, bins=250, alpha=0.5, color='g')\n",
    "plt.title('Distribution of Labels')\n",
    "plt.xlabel('Number of Images per Label')\n",
    "plt.ylabel('Number of Labels')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oversampling and Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oversampling strategy used on dataset\n",
      "1052    434\n",
      "769     434\n",
      "785     434\n",
      "787     434\n",
      "789     434\n",
      "       ... \n",
      "612     434\n",
      "611     434\n",
      "617     434\n",
      "618     434\n",
      "2457    434\n",
      "Name: encoded_label, Length: 3010, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "undersampling strategy used on dataset\n",
      "0       13\n",
      "2010    13\n",
      "2001    13\n",
      "2002    13\n",
      "2003    13\n",
      "        ..\n",
      "1005    13\n",
      "1006    13\n",
      "1007    13\n",
      "1008    13\n",
      "3009    13\n",
      "Name: encoded_label, Length: 3010, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = df_combined.drop(\"encoded_label\", axis=1)\n",
    "Y = df_combined[\"encoded_label\"]\n",
    "\n",
    "oversampler = RandomOverSampler(sampling_strategy=\"not majority\")\n",
    "X_resampled, Y_resampled = oversampler.fit_resample(X,Y)\n",
    "\n",
    "#Check if dataset is balanced after oversampling\n",
    "print(\"oversampling strategy used on dataset\")\n",
    "print(Y_resampled.value_counts())\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.hist(Y_resampled, bins=250, alpha=0.5, color='g')\n",
    "plt.title('Distribution of Labels')\n",
    "plt.xlabel('Label number')\n",
    "plt.ylabel('Number of Images per Label')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "X = df_combined.drop(\"encoded_label\", axis=1)\n",
    "Y = df_combined[\"encoded_label\"]\n",
    "\n",
    "undersampler = RandomUnderSampler(sampling_strategy=\"not minority\")\n",
    "X_resampled, Y_resampled = undersampler.fit_resample(X,Y)\n",
    "\n",
    "#Check if dataset is balanced after undersampling\n",
    "print(\"undersampling strategy used on dataset\")\n",
    "print(Y_resampled.value_counts())\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.hist(Y_resampled, bins=250, alpha=0.5, color='g')\n",
    "plt.title('Distribution of Labels')\n",
    "plt.xlabel('Label number')\n",
    "plt.ylabel('Number of Images per Label')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Nm5cEhnXQrY"
   },
   "source": [
    "# Data Augmentation and Preprocessing\n",
    "Because each pill/tablet only has one picture, the data set in itself is not ideal.\n",
    "To improve the quality of the data set, and that of the model, we augment the data.\n",
    "We do this by transforming the image, mimicking how an actual user may take a picture.\n",
    "That is, the image can be brightened, resized, rotated, sheared, cropped, and etc. Other processes are also performed to improve training of the model such as splitting the data into a training set and testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qxGoMZM6Xpo9",
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "#Convert column into strings\n",
    "dataset_df[\"image_paths\"] = dataset_df[\"image_paths\"].astype(str)\n",
    "dataset_df[\"labels\"] = dataset_df[\"labels\"].astype(str)\n",
    "\n",
    "print(dataset_df[\"image_paths\"].head())\n",
    "\n",
    "#Splitting dataset into 60/20/20\n",
    "train_df, temp_df = train_test_split(dataset_df, test_size=0.4, random_state=42)\n",
    "eval_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=1337)\n",
    "\n",
    "# Create the image data generator for the training set\n",
    "imageTrain_data = ImageDataGenerator(\n",
    "    rescale = 1./255.,\n",
    "    rotation_range = 60,\n",
    "    shear_range = 0.3,\n",
    "    zoom_range = 0.5,\n",
    "    vertical_flip = True,\n",
    "    horizontal_flip = True,\n",
    "    width_shift_range = 0.3,\n",
    "    height_shift_range = 0.3,\n",
    "    brightness_range=[0.5, 1.5],\n",
    "    fill_mode=\"nearest\",\n",
    ")\n",
    "\n",
    "train_generator = imageTrain_data.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    directory=directory,\n",
    "    target_size = (img_height, img_width),\n",
    "    batch_size = batch_size,\n",
    "    x_col = \"image_paths\",\n",
    "    y_col = \"labels\",\n",
    "    class_mode=\"categorical\",\n",
    ")\n",
    "\n",
    "# Create the image data generator for the evaluation set\n",
    "imageEval_data = ImageDataGenerator(rescale = 1./255.)\n",
    "\n",
    "\n",
    "eval_generator = imageEval_data.flow_from_dataframe(\n",
    "    dataframe=eval_df,\n",
    "    directory=directory,\n",
    "    target_size = (img_height, img_width),\n",
    "    batch_size = batch_size,\n",
    "    x_col = \"image_paths\",\n",
    "    y_col = \"labels\",\n",
    "    class_mode=\"categorical\",\n",
    ")\n",
    "\n",
    "\n",
    "# Create the image data generator for the test set\n",
    "imageTest_data = ImageDataGenerator(rescale = 1./255.)\n",
    "\n",
    "\n",
    "test_generator = imageTest_data.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    directory=directory,\n",
    "    target_size = (img_height, img_width),\n",
    "    batch_size = batch_size,\n",
    "    x_col = \"image_paths\",\n",
    "    y_col = \"labels\",\n",
    "    class_mode=\"categorical\",\n",
    ")\n",
    "\n",
    "#Display example of image augmentation\n",
    "sample_dataframe = train_df.sample(n=1).reset_index(drop=True)\n",
    "sample_generator = imageTrain_data.flow_from_dataframe(\n",
    "    dataframe=sample_dataframe,\n",
    "    directory=directory,\n",
    "    target_size = (img_height, img_width),\n",
    "    batch_size = batch_size,\n",
    "    x_col = \"image_paths\",\n",
    "    y_col = \"labels\",\n",
    "    class_mode=\"categorical\",\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "for i in range (0, 15):\n",
    "  ax = plt.subplot(5, 3, i + 1)\n",
    "  for X_column, Y_column in sample_generator:\n",
    "    plt.imshow(X_column[0])\n",
    "    break\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7-ZGIIlGXqWY"
   },
   "source": [
    "# Filtering\n",
    "Using OpenCV, we filter out any artifacts (i.e. background, lens flares, graininess, etc.) and extract the features necessary for identification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X28VD5zqX9Pu",
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def thresholding(img, alpha=0.5):\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply CLAHE to the grayscale image\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(2,2))\n",
    "    gray_clahe = clahe.apply(gray)\n",
    "\n",
    "    # Convert the grayscale image back to BGR\n",
    "    img_clahe = cv2.cvtColor(gray_clahe, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    # Blend the CLAHE image with the original image\n",
    "    result = cv2.addWeighted(img, alpha, img_clahe, 1 - alpha, 0)\n",
    "\n",
    "    return result\n",
    "\n",
    "def remove_background(image):\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply a blur\n",
    "    blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "    # Threshold the image\n",
    "    _, thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Filter out small contours based on area\n",
    "    contours = [cnt for cnt in contours if cv2.contourArea(cnt) > 500]\n",
    "\n",
    "    # Create an empty mask to store the result\n",
    "    mask = np.zeros_like(thresh)\n",
    "\n",
    "    # Draw the contours on the mask\n",
    "    cv2.drawContours(mask, contours, -1, (255), thickness=cv2.FILLED)\n",
    "\n",
    "    # Perform morphological operations\n",
    "    kernel = np.ones((3,3),np.uint8)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel, iterations = 2)\n",
    "    mask = cv2.dilate(mask,kernel,iterations = 1)\n",
    "\n",
    "    # Invert the mask\n",
    "    mask = cv2.bitwise_not(mask)\n",
    "\n",
    "    # Bitwise AND the mask and the original image\n",
    "    res = cv2.bitwise_and(image, image, mask=mask)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4zW9RMHnXyhu"
   },
   "source": [
    "# Hyperparameter Search\n",
    "To ensure the best set of hyperparameters used by the model, we enable hyperparameter search prior to training the model. This exhaustively searches the best combination of hyperparameters to be used for training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts the dataframe into a dataset\n",
    "class ImageClassificationDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.labels = self.label_encoder.fit_transform(self.labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        image_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        image = read_image(image_path)  # Open the image and convert it to a tensor\n",
    "        image = Resize((224, 224), antialias=True)(image)  # Resize the image\n",
    "        return {'pixel_values': image, 'labels': torch.tensor(label, dtype=torch.long)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XICqDptZYCI2",
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "%\n",
    "def optuna_hp_space(trial):\n",
    "    return {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-5, 5e-5, log=True),\n",
    "        \"per_device_train_batch_size\": trial.suggest_categorical(\"per_device_train_batch_size\", [16, 32, 64]),\n",
    "        \"weight_decay\": trial.suggest_float(\"weight_decay\", 0.0, 0.3),\n",
    "    }\n",
    "\n",
    "model_name = 'google/vit-base-patch16-224'\n",
    "token = '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'             # Jan's personal access token\n",
    "configuration = ViTConfig()\n",
    "\n",
    "# Select only 100 rows from the training set\n",
    "train_df = train_df.sample(n=100)\n",
    "\n",
    "# Prepend the path to the dataset folder to each file path\n",
    "train_df['image_paths'] = train_df['image_paths'].apply(lambda x: x if x.startswith('dataset') else os.path.join('dataset', x))\n",
    "\n",
    "# Split data into a training set and an evaluation set\n",
    "train_df, eval_df = train_test_split(train_df, test_size=0.2)  # Use 20% of your data for evaluation\n",
    "\n",
    "# Reset the index of the DataFrame to avoid indexing errors\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "eval_df = eval_df.reset_index(drop=True)\n",
    "\n",
    "# Convert your images and labels to tensors\n",
    "pixel_values = [image_to_tensor(image_file) for image_file in train_df['image_paths']]\n",
    "labels = train_df['labels'].to_numpy()\n",
    "\n",
    "# Create a dictionary with the pixel values and labels\n",
    "train_data = {'pixel_values': pixel_values, 'labels': labels}\n",
    "\n",
    "# Instantiate datasets\n",
    "train_dataset = ImageClassificationDataset(train_df['image_paths'], train_df['labels'].to_numpy())\n",
    "eval_dataset = ImageClassificationDataset(eval_df['image_paths'], eval_df['labels'].to_numpy())\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    gradient_accumulation_steps=1,      # prevents vanishing/exploding gradients\n",
    "    evaluation_strategy=\"steps\",    \n",
    "    max_grad_norm=1.0,                  # prevents vanishing/exploding gradients\n",
    ")\n",
    "\n",
    "\n",
    "def model_init(trial):\n",
    "    num_labels = len(np.unique(train_df['labels'].to_numpy()))\n",
    "    configuration.num_labels = num_labels           # Set the number of output units to match the number of classes\n",
    "    return ViTForImageClassification.from_pretrained(\n",
    "        model_name,\n",
    "        config=configuration,\n",
    "        from_tf=bool(\".ckpt\" in model_name),\n",
    "        cache_dir=model_name,                       # use cache to speed up model loading\n",
    "        token=token,\n",
    "        ignore_mismatched_sizes=True                # ignore image size mismatch errors\n",
    "    )\n",
    "\n",
    "trainer = Trainer(\n",
    "    model_init=model_init,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    ")\n",
    "\n",
    "\n",
    "#Execute hyperparameter search\n",
    "hypersearch = trainer.hyperparameter_search(\n",
    "    direction=\"maximize\",\n",
    "    backend=\"optuna\",\n",
    "    hp_space=optuna_hp_space,\n",
    "    n_trials=8, \n",
    ")\n",
    "\n",
    "\n",
    "print(hypersearch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Incremental Learning with Dataset Chunks\n",
    " Explore the efficiency of incremental learning with 3.3TB dataset chunks. Optimize training by iteratively downloading, processing, and removing chunks for improved resource management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: b'PillProjectDisc69/images/CLLLLUPGIX7J8MP1WWQ9WN4-CO0B5NV.CR2'\n",
      "Label: STRATTERA 10MG\n",
      "\n",
      "Image: b'PillProjectDisc98/images/PRNJ-AXZIQ!HUQKJJBP_DV44ST0KN9.CR2'\n",
      "Label: STRATTERA 10MG\n",
      "\n",
      "Image: b'PillProjectDisc10/images/79U-YY6M1UUR6F127ZMACIWPEEXHLB.JPG'\n",
      "Label: STRATTERA 10MG\n",
      "\n",
      "Image: b'PillProjectDisc11/images/7WVFV5H74!ELFNQ_GUH92E9ERM9P2K.JPG'\n",
      "Label: STRATTERA 10MG\n",
      "\n",
      "Image: b'PillProjectDisc20/images/B4CH0R9B7PEQ6GORRX-8XWOL-_G7W9_.JPG'\n",
      "Label: STRATTERA 10MG\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# read the xlsx file\n",
    "xlsx_file = \"./directory_consumer_grade_images.xlsx\"\n",
    "df = pd.read_excel(xlsx_file)\n",
    "\n",
    "# create feature extractor to tokenize data\n",
    "feature_extractor = ViTImageProcessor(\n",
    "    image_size=224,\n",
    "    do_resize=True,\n",
    "    do_normalize=True,\n",
    "    do_rescale=False,\n",
    "    image_mean=[0.5, 0.5, 0.5],\n",
    "    image_std=[0.5, 0.5, 0.5],\n",
    ")\n",
    "\n",
    "# Iterate over the third column and append to the list\n",
    "image_label_mapping = {}\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    image_path = row.iloc[2]  \n",
    "    label = row.iloc[4]  \n",
    "    if not image_path.endswith('.WMV'):\n",
    "        image_label_mapping[image_path] = label\n",
    "\n",
    "# get the image paths and labels\n",
    "image_paths = list(image_label_mapping.keys())\n",
    "labels = list(image_label_mapping.values())\n",
    "\n",
    "# encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "labels = label_encoder.fit_transform(labels)\n",
    "\n",
    "# create a dataset from the dataframe\n",
    "dataset = tf.data.Dataset.from_tensor_slices((image_paths, labels))\n",
    "dataset_df = pd.DataFrame(list(dataset.as_numpy_iterator()), columns=['image_paths', 'labels'])\n",
    "\n",
    "# print the first 5 image paths and decoded labels\n",
    "for image, label in dataset.take(5):\n",
    "  print(\"Image:\", image.numpy())\n",
    "  print(\"Label:\", label_encoder.inverse_transform([label.numpy()])[0])\n",
    "  print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1228\n",
      "410\n",
      "410\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training, validation, and test sets (60/20/20)\n",
    "train_df, temp_df = train_test_split(dataset_df, test_size=0.4, random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "\n",
    "# Create TensorFlow datasets\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_df['image_paths'].values, train_df['labels'].values))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_df['image_paths'].values, val_df['labels'].values))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_df['image_paths'].values, test_df['labels'].values))\n",
    "\n",
    "# Shuffle and batch the datasets\n",
    "train_dataset = train_dataset.shuffle(buffer_size=len(train_df)).batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "val_dataset = val_dataset.batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "# Load the first batch of data\n",
    "first_batch = next(iter(train_dataset))\n",
    "\n",
    "# Unpack the batch\n",
    "image_paths, labels = first_batch\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "for i in range(len(image_paths)):\n",
    "    image_path_str = image_paths[i].numpy().decode('utf-8')\n",
    "    image = Image.open(BytesIO(requests.get(DATASET_URL + image_path_str).content))\n",
    "    ax = plt.subplot(8, 8, i + 1) \n",
    "    plt.imshow(image)\n",
    "    plt.title(label_encoder.inverse_transform([labels[i].numpy()])[0])\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JzwPHUrRYCdM"
   },
   "source": [
    "# Model Training\n",
    "We train the model using the best hyperparameters on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if CUDA is available and set the device accordingly\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class ViTForImageClassification(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        # self.vit = ViTModel(config, add_pooling_layer=False)\n",
    "        # self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
    "        self.vit = ViTModel(config, add_pooling_layer=False).to(device)                # Move model to Nvidia card\n",
    "        self.classifier = nn.Linear(config.hidden_size, config.num_labels).to(device)  # Move model to Nvidia card\n",
    "\n",
    "    def forward(self, pixel_values, labels):\n",
    "        outputs = self.vit(pixel_values=pixel_values)\n",
    "        logits = self.classifier(outputs.last_hidden_state[:, 0])\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(logits, labels)\n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )\n",
    "    \n",
    "\n",
    "# compute accuracy\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    if isinstance(labels, int):\n",
    "        labels = [labels]\n",
    "    accuracy = load_metric(\"accuracy\").compute(predictions=predictions, references=labels)\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    return accuracy\n",
    "    \n",
    "        \n",
    "# create feature extractor to tokenize data\n",
    "feature_extractor = ViTImageProcessor(\n",
    "    image_size=224,\n",
    "    do_resize=True,\n",
    "    do_normalize=True,\n",
    "    do_rescale=False,\n",
    "    image_mean=[0.5, 0.5, 0.5],\n",
    "    image_std=[0.5, 0.5, 0.5],\n",
    ")\n",
    "\n",
    "\n",
    "# Define a function to load and preprocess the images\n",
    "def load_and_preprocess_images(example):\n",
    "    # Load the image from the file\n",
    "    image = Image.open('dataset/' + example['image_paths'])\n",
    "    image = np.array(image, dtype=np.uint8)\n",
    "    image = np.moveaxis(image, source=-1, destination=0)\n",
    "    # Preprocess the image\n",
    "    inputs = feature_extractor(images=[image])\n",
    "    pixel_values = torch.tensor(inputs['pixel_values'][0], dtype=torch.float32).to(device)  # convert to tensor and move to device\n",
    "    label = int(example['labels'])\n",
    "    return {'pixel_values': pixel_values, 'labels': label}\n",
    "\n",
    "\n",
    "# define a custom data collator\n",
    "def data_collator(features):\n",
    "    pixel_values = [torch.tensor(feature['pixel_values'], dtype=torch.float32).to(device) for feature in features]  # Move to device\n",
    "    labels = [feature['labels'] for feature in features]\n",
    "    pixel_values = torch.stack(pixel_values)\n",
    "    return {'pixel_values': pixel_values, 'labels': torch.tensor(labels).to(device)}  # Move to device\n",
    "\n",
    "\n",
    "num_classes = labels.max() + 1\n",
    "\n",
    "# Define the features of the dataset\n",
    "features = Features({\n",
    "    'labels': ClassLabel(num_classes=num_classes),\n",
    "    'img': Array3D(dtype=\"int64\", shape=(3, 32, 32)),\n",
    "    'pixel_values': Array3D(dtype=\"float32\", shape=(3, 224, 224)),\n",
    "})\n",
    "\n",
    "# Generate lists of image paths and labels for training dataset\n",
    "train_image_paths = train_df[\"image_paths\"].tolist()\n",
    "train_labels = train_df[\"labels\"].tolist()\n",
    "\n",
    "# Create a dictionary with the image paths and labels\n",
    "train_dict = {'image_paths': train_image_paths, 'labels': train_labels}\n",
    "\n",
    "# Create the dataset\n",
    "train_dataset = Dataset.from_dict(train_dict)\n",
    "\n",
    "# Apply the function to the dataset\n",
    "train_dataset = train_dataset.map(load_and_preprocess_images)\n",
    "train_dataset = train_dataset.remove_columns(['image_paths'])\n",
    "\n",
    "\n",
    "# Repeat the same process for the evaluation and test datasets\n",
    "eval_image_paths = eval_df[\"image_paths\"].tolist()\n",
    "eval_labels = eval_df[\"labels\"].tolist()\n",
    "eval_dict = {'image_paths': eval_image_paths, 'labels': eval_labels}\n",
    "eval_dataset = Dataset.from_dict(eval_dict)\n",
    "eval_dataset = eval_dataset.map(load_and_preprocess_images)\n",
    "eval_dataset = eval_dataset.remove_columns(['image_paths'])\n",
    "\n",
    "\n",
    "test_image_paths = test_df[\"image_paths\"].tolist()\n",
    "test_labels = test_df[\"labels\"].tolist()\n",
    "test_dict = {'image_paths': test_image_paths, 'labels': test_labels}\n",
    "test_dataset = Dataset.from_dict(test_dict)\n",
    "test_dataset = test_dataset.map(load_and_preprocess_images)\n",
    "test_dataset = test_dataset.remove_columns(['image_paths'])\n",
    "\n",
    "\n",
    "# Load the pre-trained model\n",
    "pretrained_model = ViTModel.from_pretrained('google/vit-base-patch16-224')\n",
    "\n",
    "# Define your custom model\n",
    "config = pretrained_model.config\n",
    "config.num_labels = num_labels\n",
    "model = ViTForImageClassification(config)\n",
    "\n",
    "# Copy the pre-trained weights to your custom model\n",
    "model.vit = pretrained_model\n",
    "\n",
    "\n",
    "\n",
    "early_stopping_callback = EarlyStoppingCallback(\n",
    "    early_stopping_patience=10,  # Number of evaluations with no improvement after which training will be stopped.\n",
    "    early_stopping_threshold=0.0  # Threshold for measuring the new optimum, to only focus on significant changes.\n",
    ")\n",
    "\n",
    "\n",
    "# create the training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    num_train_epochs=50,              # total number of training epochs\n",
    "    per_device_train_batch_size=16,  # batch size per device during training\n",
    "    per_device_eval_batch_size=16,   # batch size for evaluation\n",
    "    warmup_steps=75,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.018,               # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    logging_steps=10,\n",
    "    logging_first_step=True,\n",
    "    logging_strategy='steps',\n",
    "    evaluation_strategy='epoch',\n",
    "    eval_steps=10,  \n",
    "    save_strategy='epoch',\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='accuracy',\n",
    "    greater_is_better=True,\n",
    "    learning_rate=3e-5,\n",
    "    gradient_accumulation_steps=1,      # prevents vanishing/exploding gradients\n",
    "    max_grad_norm=1.0,                  # prevents vanishing/exploding gradients\n",
    "    # fp16=True                     # mixed precision training; enable if using nVidia graphics cards\n",
    ")\n",
    "\n",
    "class CustomTrainer(Trainer):\n",
    "    def get_train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.args.train_batch_size, shuffle=True, collate_fn=self.data_collator)\n",
    "    \n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        # Move inputs to device\n",
    "        for key, value in inputs.items():\n",
    "            inputs[key] = value.to(device)\n",
    "\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        labels = inputs[\"labels\"]  # Get labels from inputs\n",
    "\n",
    "        loss = torch.nn.functional.cross_entropy(logits, labels)\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "        \n",
    "mainTrainer = CustomTrainer (\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[early_stopping_callback]  # Add the early stopping callback\n",
    "\n",
    ")\n",
    "\n",
    "# mainTrainer.train()\n",
    "# model.save_pretrained('./saved_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E0FQOqnPYEg1"
   },
   "source": [
    "# Model Testing\n",
    "We test the model on the test set to validate training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('./saved_model/model_weights.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to load and preprocess the images for testing\n",
    "def load_and_preprocess_test_images(example):\n",
    "    image = Image.open('dataset/' + example['image_paths'])\n",
    "    image = np.array(image, dtype=np.uint8)\n",
    "    image = np.moveaxis(image, source=-1, destination=0)\n",
    "    inputs = feature_extractor(images=[image])\n",
    "    pixel_values = torch.tensor(inputs['pixel_values'][0], dtype=torch.float32).to(device)\n",
    "    label = int(example['labels'])\n",
    "    return {'pixel_values': pixel_values, 'labels': label}\n",
    "\n",
    "# Apply the function to the test dataset\n",
    "test_dataset = Dataset.from_dict(test_dict)\n",
    "test_dataset = test_dataset.map(load_and_preprocess_test_images)\n",
    "test_dataset = test_dataset.remove_columns(['image_paths'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Create a DataLoader for the test dataset\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=data_collator)\n",
    "\n",
    "# Lists to store predictions and true labels\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "all_losses = []\n",
    "\n",
    "# Iterate through the test dataset\n",
    "for batch in test_dataloader:\n",
    "    with torch.no_grad():\n",
    "        # Forward pass\n",
    "        inputs = batch['pixel_values']\n",
    "        labels = batch['labels']\n",
    "        outputs = model(pixel_values=inputs, labels=labels)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        # Convert logits to predictions\n",
    "        predictions = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "\n",
    "        loss = outputs.loss.item()\n",
    "\n",
    "        # Append predictions and true labels to lists\n",
    "        all_predictions.extend(predictions)\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_losses.append(loss)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "all_predictions = np.array(all_predictions)\n",
    "all_labels = np.array(all_labels)\n",
    "all_losses = np.array(all_losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy and other metrics\n",
    "accuracy = accuracy_score(all_labels, all_predictions)\n",
    "precision, recall, fscore, _ = precision_recall_fscore_support(all_labels, all_predictions, average='weighted')\n",
    "classification_report_str = classification_report(all_labels, all_predictions)\n",
    "\n",
    "# Print or use the metrics as needed\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {fscore}\")\n",
    "print(\"Classification Report:\\n\", tabulate([[''] + classification_report_str.split('\\n')[0].split()] + [line.split() for line in classification_report_str.split('\\n')[2:-5]], headers='firstrow', tablefmt='grid'))\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(all_losses, label='Test Loss')\n",
    "plt.xlabel('Batch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(all_labels, all_predictions, 'bo', markersize=3)\n",
    "plt.xlabel('True Labels')\n",
    "plt.ylabel('Predicted Labels')\n",
    "plt.title('True vs Predicted Labels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Evaluate the trained model on the eval dataset\n",
    "# test_results = mainTrainer.evaluate(eval_dataset=test_dataset)\n",
    "\n",
    "# epoch_accuracies = []\n",
    "# epoch_test_loss = []\n",
    "\n",
    "# for epoch in range(mainTrainer.args.num_train_epochs):\n",
    "#     test_accuracy = test_results['eval_accuracy']\n",
    "#     test_loss = test_results['eval_loss']\n",
    "#     epoch_test_loss.append(test_loss)\n",
    "#     epoch_accuracies.append(test_accuracy)\n",
    "#     print(f\"Epoch {epoch + 1} - Test Accuracy: {test_accuracy}\")\n",
    "#     print(f\"Epoch {epoch + 1} - Test Loss: {test_loss}\")\n",
    "\n",
    "# # Plot accuracy per epoch\n",
    "# plt.plot(range(1, mainTrainer.args.num_train_epochs + 1), epoch_accuracies, marker='o')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.title('Accuracy per Epoch')\n",
    "# plt.show()\n",
    "\n",
    "# # Plot loss per epoch\n",
    "# plt.plot(range(1, mainTrainer.args.num_train_epochs + 1), epoch_test_loss, marker='o')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.title('Loss per Epoch')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7bWzoJ-yYHsD"
   },
   "source": [
    "# Save the Model\n",
    "We serialize the model for checkpointing and for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T22:33:19.579917Z",
     "start_time": "2024-01-04T22:33:19.576933Z"
    },
    "id": "yQvYHhG1YJ3D"
   },
   "outputs": [],
   "source": [
    "#Save Directory\n",
    "save_directory = \"saved_model\"\n",
    "\n",
    "# Save the trained model\n",
    "mainTrainer.save_model(save_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hvkLV3hsYYKm"
   },
   "source": [
    "# Predicting using the base model\n",
    "Utilizing the base model, we predict the label of an image and produce up to five responses with their corresponding relevance scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T22:33:19.584350Z",
     "start_time": "2024-01-04T22:33:19.579586Z"
    },
    "id": "y7ra0pG7YXZq"
   },
   "outputs": [],
   "source": [
    "# Replace this with your own path\n",
    "path = \"00002-3228-30_NLMIMAGE10_391E1C80.jpg\"\n",
    "\n",
    "def predict(path, top_k):\n",
    "    # read the image using openCV\n",
    "    image = cv2.imread(path)\n",
    "    # applying the thresholding function for preprocessing\n",
    "    bg1 = remove_background(image)\n",
    "    thresh1 = thresholding(bg1)\n",
    "    image = thresh1\n",
    "    # openCV reads image in BGR, convert it to RGB for tensorflow\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) \n",
    "    # resize the image\n",
    "    image = tf.image.resize(image, [256, 256])\n",
    "    image /= 255.0 \n",
    "    \n",
    "    # This is to show the image after preprocessing. Saved this for debugging.\n",
    "    # plt.figure(figsize=(10, 10))\n",
    "    # plt.imshow(image)\n",
    "    \n",
    "    # ViTFeatureExtractor is deprecated (still work but will give warning). For transformer of version 5+, AutoImageProcessor is used.\n",
    "    # load the model. Should be replaced with our own model later\n",
    "    # model_directory = our_model_dic\n",
    "    # feature_extractor = AutoImageProcessor.from_pretrained(model_directory)\n",
    "    # model = ViTForImageClassification.from_pretrained(model_directory, return_dict=False)\n",
    "     \n",
    "    feature_extractor = AutoImageProcessor.from_pretrained('google/vit-base-patch16-224')\n",
    "    model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224')\n",
    "    \n",
    "    inputs = feature_extractor(images=image, return_tensors=\"pt\")\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    \n",
    "    # get the top five predictions\n",
    "    top_k_values, top_k_indices = torch.topk(logits, top_k)\n",
    "\n",
    "    # pack everything in a list \n",
    "    top_k_predictions = [{\"class_idx\": idx.item(), \"score\": score.item()} for idx, score in zip(top_k_indices[0], top_k_values[0])]\n",
    "    for item in top_k_predictions:\n",
    "        item[\"class_label\"] = model.config.id2label[item[\"class_idx\"]]\n",
    "        \n",
    "    for item in top_k_predictions:\n",
    "        del(item[\"class_idx\"])\n",
    "    \n",
    "    return top_k_predictions \n",
    "   \n",
    "\n",
    "top_k_predictions = predict(path, 5)\n",
    "\n",
    "# print the five top predictions and the score they have\n",
    "for prediction in top_k_predictions:\n",
    "    score = prediction[\"score\"]\n",
    "    class_label = prediction[\"class_label\"]\n",
    "    print(f\"Predicted Class: {class_label}, Score: {score}\")\n",
    "\n",
    "# check the whole list\n",
    "print()\n",
    "print(top_k_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting using the saved model\n",
    "Utilizing the trained model, we predict the label of an image and produce up to five responses with their corresponding relevance scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace this with your own path\n",
    "path = \"00002-3228-30_NLMIMAGE10_391E1C80.jpg\"\n",
    "\n",
    "def local_predict(path, k):\n",
    "    # First initialized the customized model and the classes that will be used in preprocessing:\n",
    "    # Check if CUDA is available and set the device accordingly\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    class ViTForImageClassification(nn.Module):\n",
    "        def __init__(self, config):\n",
    "            super().__init__()\n",
    "            self.config = config\n",
    "            # self.vit = ViTModel(config, add_pooling_layer=False)\n",
    "            # self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
    "            self.vit = ViTModel(config, add_pooling_layer=False).to(device)                # Move model to Nvidia card\n",
    "            self.classifier = nn.Linear(config.hidden_size, config.num_labels).to(device)  # Move model to Nvidia card\n",
    "\n",
    "        def forward(self, pixel_values, labels):\n",
    "            outputs = self.vit(pixel_values=pixel_values)\n",
    "            logits = self.classifier(outputs.last_hidden_state[:, 0])\n",
    "            loss = None\n",
    "            if labels is not None:\n",
    "                loss_fct = nn.CrossEntropyLoss()\n",
    "                loss = loss_fct(logits, labels)\n",
    "            return SequenceClassifierOutput(\n",
    "                loss=loss,\n",
    "                logits=logits,\n",
    "                hidden_states=outputs.hidden_states,\n",
    "                attentions=outputs.attentions,\n",
    "            )\n",
    "    \n",
    "\n",
    "    # compute accuracy\n",
    "    def compute_metrics(eval_pred):\n",
    "        logits, labels = eval_pred\n",
    "        predictions = np.argmax(logits, axis=-1)\n",
    "        if isinstance(labels, int):\n",
    "            labels = [labels]\n",
    "        accuracy = load_metric(\"accuracy\").compute(predictions=predictions, references=labels)\n",
    "        print(f\"Accuracy: {accuracy}\")\n",
    "        return accuracy\n",
    "\n",
    "        \n",
    "    # create feature extractor to tokenize data\n",
    "    feature_extractor = ViTImageProcessor(\n",
    "        image_size=224,\n",
    "        do_resize=True,\n",
    "        do_normalize=True,\n",
    "        do_rescale=False,\n",
    "        image_mean=[0.5, 0.5, 0.5],\n",
    "        image_std=[0.5, 0.5, 0.5],\n",
    "    )\n",
    "\n",
    "\n",
    "    # define a custom data collator\n",
    "    def data_collator(features):\n",
    "        pixel_values = [torch.tensor(feature['pixel_values'], dtype=torch.float32).to(device) for feature in features]  # Move to device\n",
    "        labels = [feature['labels'] for feature in features]\n",
    "        pixel_values = torch.stack(pixel_values)\n",
    "        return {'pixel_values': pixel_values, 'labels': torch.tensor(labels).to(device)}  # Move to device\n",
    "\n",
    "    # num_classes = labels.max() + 1\n",
    "    num_classes = 2113\n",
    "\n",
    "\n",
    "    # Define the features of the dataset\n",
    "    features = Features({\n",
    "        'labels': ClassLabel(num_classes=num_classes),\n",
    "        'img': Array3D(dtype=\"int64\", shape=(3, 32, 32)),\n",
    "        'pixel_values': Array3D(dtype=\"float32\", shape=(3, 224, 224)),\n",
    "    })\n",
    "\n",
    "\n",
    "    train_dataset = Dataset.from_dict({'pixel_values': 'pixel_values', 'labels': 'label6789101'})\n",
    "\n",
    "\n",
    "    # Load the pre-trained model\n",
    "    pretrained_model = ViTModel.from_pretrained('google/vit-base-patch16-224')\n",
    "\n",
    "    # Define your custom model\n",
    "    config = pretrained_model.config\n",
    "    config.num_labels = 2112\n",
    "    model = ViTForImageClassification(config)\n",
    "\n",
    "    # Copy the pre-trained weights to your custom model\n",
    "    model.vit = pretrained_model\n",
    "\n",
    "    model.load_state_dict(torch.load('./saved_model/model_weights.pth'))\n",
    "\n",
    "\n",
    "    early_stopping_callback = EarlyStoppingCallback(\n",
    "        early_stopping_patience=10,  # Number of evaluations with no improvement after which training will be stopped.\n",
    "        early_stopping_threshold=0.0  # Threshold for measuring the new optimum, to only focus on significant changes.\n",
    "    )\n",
    "\n",
    "\n",
    "    # create the training arguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir='./results',          # output directory\n",
    "        num_train_epochs=50,              # total number of training epochs\n",
    "        per_device_train_batch_size=16,  # batch size per device during training\n",
    "        per_device_eval_batch_size=16,   # batch size for evaluation\n",
    "        warmup_steps=75,                # number of warmup steps for learning rate scheduler\n",
    "        weight_decay=0.018,               # strength of weight decay\n",
    "        logging_dir='./logs',            # directory for storing logs\n",
    "        logging_steps=10,\n",
    "        logging_first_step=True,\n",
    "        logging_strategy='steps',\n",
    "        evaluation_strategy='epoch',\n",
    "        eval_steps=10,  \n",
    "        save_strategy='epoch',\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model='accuracy',\n",
    "        greater_is_better=True,\n",
    "        learning_rate=3e-5,\n",
    "        gradient_accumulation_steps=1,      # prevents vanishing/exploding gradients\n",
    "        max_grad_norm=1.0,                  # prevents vanishing/exploding gradients\n",
    "        # fp16=True                     # mixed precision training; enable if using nVidia graphics cards\n",
    "    )\n",
    "\n",
    "    class CustomTrainer(Trainer):\n",
    "        def get_train_dataloader(self):\n",
    "            return DataLoader(self.train_dataset, batch_size=self.args.train_batch_size, shuffle=True, collate_fn=self.data_collator)\n",
    "\n",
    "        def compute_loss(self, model, inputs, return_outputs=False):\n",
    "            # Move inputs to device\n",
    "            for key, value in inputs.items():\n",
    "                inputs[key] = value.to(device)\n",
    "\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits\n",
    "\n",
    "            labels = inputs[\"labels\"]  # Get labels from inputs\n",
    "\n",
    "            loss = torch.nn.functional.cross_entropy(logits, labels)\n",
    "            return (loss, outputs) if return_outputs else loss\n",
    "        \n",
    "    mainTrainer = CustomTrainer (\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=train_dataset,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[early_stopping_callback]  # Add the early stopping callback\n",
    "\n",
    "    )\n",
    "\n",
    "#     print('done')\n",
    "    \n",
    "    # Second preprocess the input:\n",
    "    # OpenCV follows BGR convention and PIL follows RGB color convention\n",
    "    def load_and_preprocess_user_input(example):\n",
    "#         thresholding(image) not used for now cause it will make the prediction worse      \n",
    "        image = Image.open(path)\n",
    "        image = np.array(image, dtype=np.uint8)\n",
    "        image = np.moveaxis(image, source=-1, destination=0)\n",
    "        inputs = feature_extractor(images=[image])\n",
    "        pixel_values = torch.tensor(inputs['pixel_values'][0], dtype=torch.float32).to(device)  # convert to tensor and move to device\n",
    "        label = example['labels']\n",
    "        return {'pixel_values': pixel_values, 'labels': label}\n",
    "    \n",
    "    # Create the pandas DataFrame using user input. The lable is a random number, won't be used so can be any value.\n",
    "    user_data = [[path, 987]]\n",
    " \n",
    "    # Create the user input pandas DataFrame\n",
    "    user_df = pd.DataFrame(user_data, columns=['image_paths', 'labels'])\n",
    "\n",
    "    image_paths = user_df['image_paths'].values\n",
    "    labels = user_df[\"labels\"].values\n",
    "    \n",
    "    # Transfer the user input into the object that can be accepted by the model\n",
    "    user_dataset = tf.data.Dataset.from_tensor_slices((image_paths, labels))\n",
    "    user_dataset_df = pd.DataFrame(list(user_dataset.as_numpy_iterator()), columns=['image_paths', 'labels'])\n",
    " \n",
    "    user_test_image_paths = user_dataset_df[\"image_paths\"].tolist()\n",
    "    user_test_labels = user_dataset_df[\"labels\"].tolist()\n",
    "    user_test_dict = {'image_paths': user_test_image_paths, 'labels': user_test_labels}\n",
    "    user_test_dataset = Dataset.from_dict(user_test_dict)\n",
    "    user_test_dataset = user_test_dataset.map(load_and_preprocess_user_input)\n",
    "    user_test_dataset = user_test_dataset.remove_columns(['image_paths'])\n",
    "    \n",
    "    # Third use the model to predict:\n",
    "    outputs = mainTrainer.predict(user_test_dataset)\n",
    "    \n",
    "    # Fourth use the saved encoder to decode the predictions\n",
    "    y_pred = np.argsort(outputs.predictions, axis=1)[:, ::-1][:, :5]\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.classes_ = np.load('encoder/encoder.npy', allow_pickle=True)\n",
    "    \n",
    "    # Fifth return the list containing top k possibilities\n",
    "    result={}\n",
    "    i = 0\n",
    "    while i < k:\n",
    "        result[i+1] = encoder.inverse_transform([y_pred[0][i]])[0]\n",
    "#         print('Rank '+ str(i+1) + ' possibility of the pill: ' + encoder.inverse_transform([y_pred[0][i]])[0])\n",
    "        i += 1\n",
    "    return result\n",
    "\n",
    "results = local_predict(path, 5)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if CUDA is available and set the device accordingly\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class ViTForImageClassification(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        # self.vit = ViTModel(config, add_pooling_layer=False)\n",
    "        # self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
    "        self.vit = ViTModel(config, add_pooling_layer=False).to(device)                # Move model to Nvidia card\n",
    "        self.classifier = nn.Linear(config.hidden_size, config.num_labels).to(device)  # Move model to Nvidia card\n",
    "\n",
    "    def forward(self, pixel_values, labels):\n",
    "        outputs = self.vit(pixel_values=pixel_values)\n",
    "        logits = self.classifier(outputs.last_hidden_state[:, 0])\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(logits, labels)\n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )\n",
    "    \n",
    "\n",
    "# compute accuracy\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    if isinstance(labels, int):\n",
    "        labels = [labels]\n",
    "    accuracy = load_metric(\"accuracy\").compute(predictions=predictions, references=labels)\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    return accuracy\n",
    "    \n",
    "        \n",
    "# create feature extractor to tokenize data\n",
    "feature_extractor = ViTImageProcessor(\n",
    "    image_size=224,\n",
    "    do_resize=True,\n",
    "    do_normalize=True,\n",
    "    do_rescale=False,\n",
    "    image_mean=[0.5, 0.5, 0.5],\n",
    "    image_std=[0.5, 0.5, 0.5],\n",
    ")\n",
    "\n",
    "\n",
    "# Define a function to load and preprocess the images\n",
    "# def load_and_preprocess_images(example):\n",
    "#     # Load the image from the file\n",
    "#     image = Image.open('dataset/' + example['image_paths'])\n",
    "#     image = np.array(image, dtype=np.uint8)\n",
    "#     image = np.moveaxis(image, source=-1, destination=0)\n",
    "#     # Preprocess the image\n",
    "#     inputs = feature_extractor(images=[image])\n",
    "#     pixel_values = torch.tensor(inputs['pixel_values'][0], dtype=torch.float32).to(device)  # convert to tensor and move to device\n",
    "#     label = int(example['labels'])\n",
    "#     return {'pixel_values': pixel_values, 'labels': label}\n",
    "\n",
    "\n",
    "# define a custom data collator\n",
    "def data_collator(features):\n",
    "    pixel_values = [torch.tensor(feature['pixel_values'], dtype=torch.float32).to(device) for feature in features]  # Move to device\n",
    "    labels = [feature['labels'] for feature in features]\n",
    "    pixel_values = torch.stack(pixel_values)\n",
    "    return {'pixel_values': pixel_values, 'labels': torch.tensor(labels).to(device)}  # Move to device\n",
    "\n",
    "# num_classes = labels.max() + 1\n",
    "num_classes = 2113\n",
    "\n",
    "\n",
    "# Define the features of the dataset\n",
    "features = Features({\n",
    "    'labels': ClassLabel(num_classes=num_classes),\n",
    "    'img': Array3D(dtype=\"int64\", shape=(3, 32, 32)),\n",
    "    'pixel_values': Array3D(dtype=\"float32\", shape=(3, 224, 224)),\n",
    "})\n",
    "\n",
    "# # Generate lists of image paths and labels for training dataset\n",
    "# train_image_paths = train_df[\"image_paths\"].tolist()\n",
    "# train_labels = train_df[\"labels\"].tolist()\n",
    "\n",
    "# # Create a dictionary with the image paths and labels\n",
    "# train_dict = {'image_paths': train_image_paths, 'labels': train_labels}\n",
    "\n",
    "# # Create the dataset\n",
    "# train_dataset = Dataset.from_dict(train_dict)\n",
    "\n",
    "# # Apply the function to the dataset\n",
    "# train_dataset = train_dataset.map(load_and_preprocess_images)\n",
    "# train_dataset = train_dataset.remove_columns(['image_paths'])\n",
    "\n",
    "\n",
    "# # Repeat the same process for the evaluation and test datasets\n",
    "# eval_image_paths = eval_df[\"image_paths\"].tolist()\n",
    "# eval_labels = eval_df[\"labels\"].tolist()\n",
    "# eval_dict = {'image_paths': eval_image_paths, 'labels': eval_labels}\n",
    "# eval_dataset = Dataset.from_dict(eval_dict)\n",
    "# eval_dataset = eval_dataset.map(load_and_preprocess_images)\n",
    "# eval_dataset = eval_dataset.remove_columns(['image_paths'])\n",
    "\n",
    "\n",
    "# test_image_paths = test_df[\"image_paths\"].tolist()\n",
    "# test_labels = test_df[\"labels\"].tolist()\n",
    "# test_dict = {'image_paths': test_image_paths, 'labels': test_labels}\n",
    "# test_dataset = Dataset.from_dict(test_dict)\n",
    "# test_dataset = test_dataset.map(load_and_preprocess_images)\n",
    "# test_dataset = test_dataset.remove_columns(['image_paths'])\n",
    "\n",
    "train_dataset = Dataset.from_dict({'pixel_values': 'pixel_values', 'labels': 'label6789101'})\n",
    "\n",
    "\n",
    "# Load the pre-trained model\n",
    "pretrained_model = ViTModel.from_pretrained('google/vit-base-patch16-224')\n",
    "\n",
    "# Define your custom model\n",
    "config = pretrained_model.config\n",
    "config.num_labels = 2112\n",
    "model = ViTForImageClassification(config)\n",
    "\n",
    "# Copy the pre-trained weights to your custom model\n",
    "model.vit = pretrained_model\n",
    "\n",
    "model.load_state_dict(torch.load('./saved_model/model_weights.pth'))\n",
    "\n",
    "\n",
    "early_stopping_callback = EarlyStoppingCallback(\n",
    "    early_stopping_patience=10,  # Number of evaluations with no improvement after which training will be stopped.\n",
    "    early_stopping_threshold=0.0  # Threshold for measuring the new optimum, to only focus on significant changes.\n",
    ")\n",
    "\n",
    "\n",
    "# create the training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    num_train_epochs=50,              # total number of training epochs\n",
    "    per_device_train_batch_size=16,  # batch size per device during training\n",
    "    per_device_eval_batch_size=16,   # batch size for evaluation\n",
    "    warmup_steps=75,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.018,               # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    logging_steps=10,\n",
    "    logging_first_step=True,\n",
    "    logging_strategy='steps',\n",
    "    evaluation_strategy='epoch',\n",
    "    eval_steps=10,  \n",
    "    save_strategy='epoch',\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='accuracy',\n",
    "    greater_is_better=True,\n",
    "    learning_rate=3e-5,\n",
    "    gradient_accumulation_steps=1,      # prevents vanishing/exploding gradients\n",
    "    max_grad_norm=1.0,                  # prevents vanishing/exploding gradients\n",
    "    # fp16=True                     # mixed precision training; enable if using nVidia graphics cards\n",
    ")\n",
    "\n",
    "class CustomTrainer(Trainer):\n",
    "    def get_train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.args.train_batch_size, shuffle=True, collate_fn=self.data_collator)\n",
    "    \n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        # Move inputs to device\n",
    "        for key, value in inputs.items():\n",
    "            inputs[key] = value.to(device)\n",
    "\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        labels = inputs[\"labels\"]  # Get labels from inputs\n",
    "\n",
    "        loss = torch.nn.functional.cross_entropy(logits, labels)\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "        \n",
    "mainTrainer = CustomTrainer (\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=train_dataset,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[early_stopping_callback]  # Add the early stopping callback\n",
    "\n",
    ")\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenCV follows BGR convention and PIL follows RGB color convention\n",
    "def load_and_preprocess_images2(example):\n",
    "#     image = cv2.imread('00002-3228-30_NLMIMAGE10_391E1C80.jpg')\n",
    "    # applying the thresholding function for preprocessing\n",
    "#     image = thresholding(image)\n",
    "    # openCV reads image in BGR, convert it to RGB for tensorflow\n",
    "#     image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) \n",
    "#     image = tf.image.resize(image, [256, 256])\n",
    "#     image /= 255.0 \n",
    "    image = Image.open('00002-3228-30_NLMIMAGE10_391E1C80.jpg')\n",
    "    image = np.array(image, dtype=np.uint8)\n",
    "    image = np.moveaxis(image, source=-1, destination=0)\n",
    "    # Preprocess the image\n",
    "    inputs = feature_extractor(images=[image])\n",
    "    pixel_values = torch.tensor(inputs['pixel_values'][0], dtype=torch.float32).to(device)  # convert to tensor and move to device\n",
    "    label = example['labels']\n",
    "    return {'pixel_values': pixel_values, 'labels': label}\n",
    "\n",
    "\n",
    "# Create the pandas DataFrame\n",
    "user_data = [['00002-3228-30_NLMIMAGE10_391E1C80.jpg', 987]]\n",
    " \n",
    "# Create the pandas DataFrame\n",
    "user_df = pd.DataFrame(user_data, columns=['image_paths', 'labels'])\n",
    "\n",
    "image_paths = user_df['image_paths'].values\n",
    "labels = user_df[\"labels\"].values\n",
    "\n",
    "user_dataset = tf.data.Dataset.from_tensor_slices((image_paths, labels))\n",
    "user_dataset_df = pd.DataFrame(list(user_dataset.as_numpy_iterator()), columns=['image_paths', 'labels'])\n",
    " \n",
    "\n",
    "user_test_image_paths = user_dataset_df[\"image_paths\"].tolist()\n",
    "user_test_labels = user_dataset_df[\"labels\"].tolist()\n",
    "user_test_dict = {'image_paths': user_test_image_paths, 'labels': user_test_labels}\n",
    "user_test_dataset = Dataset.from_dict(user_test_dict)\n",
    "user_test_dataset = user_test_dataset.map(load_and_preprocess_images2)\n",
    "user_test_dataset = user_test_dataset.remove_columns(['image_paths'])\n",
    "print(user_test_dataset)\n",
    "\n",
    "# test_dict2 = {'pixel_values': pixel_values, 'labels': 137}\n",
    "\n",
    "# test_dict2 = {'image_paths': '00002-3228-30_NLMIMAGE10_391E1C80.jpg', 'labels': 137}\n",
    "# test_dataset2 = datasets.DatasetDict(test_dict2)\n",
    "# test_dataset2 = Dataset.from_dict(test_dict2)\n",
    "# test_dataset2 = test_dataset2.map(load_and_preprocess_images2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = mainTrainer.predict(user_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = outputs.predictions.argmax(1)\n",
    "y_pred = np.argsort(outputs.predictions, axis=1)[:, ::-1][:, :5]\n",
    "encoder = LabelEncoder()\n",
    "encoder.classes_ = np.load('encoder/encoder.npy', allow_pickle=True)\n",
    "print(y_pred[0][4])\n",
    "top_5 = y_pred[0]\n",
    "i = 0\n",
    "result={}\n",
    "while i < 5:\n",
    "    result[i+1] = encoder.inverse_transform([y_pred[0][i]])[0]\n",
    "    print('Rank ' + str(i+1) + ' possibility of the pill: ' + str(encoder.inverse_transform([y_pred[0][i]])[0]))\n",
    "    i += 1\n",
    "# label_encoder.inverse_transform([y_pred[0]])[0]\n",
    "# print(outputs.predictions)\n",
    "print(result)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
